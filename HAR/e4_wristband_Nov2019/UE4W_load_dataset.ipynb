{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1WbviRoNfMEZwPiA0Jm0FruV9l8tODu_e","timestamp":1656703965031},{"file_id":"1RkiXI3GhB-rNtyUp_VYw05xiiuD_oDFA","timestamp":1612028534003}],"authorship_tag":"ABX9TyPXijec2U9qw6dQANXU2dwj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Khc4g511HMYk"},"source":["#UE4W_load_dataset.ipynb\n","\n","This is an enhancement of load_ue4w_demo.ipynb to include more of the load_dataset functions for the 'Unlabeled E4 Wristband' (UE4W) dataset which is on Zenodo https://doi.org/10.5281/zenodo.6898243\n","\n","In particular this version adds the physiological data sensors in addition to the motion (acceleration) data.  Since this dataset is unlabeled only X, y, and sub arrays are returned - there is no train/valid/test split.  Also y and sub are only for compatibility, all y entries are set to \"unk\"nown and all sub entries are set to 1.\n","\n","For updates please check our [IMICS lab git repository](https://github.com/imics-lab) \n","\n","<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n","\n","[Lee B. Hinkle](https://userweb.cs.txstate.edu/~lbh31/), Texas State University, [IMICS Lab](https://imics.wp.txstate.edu/)  \n","TODO:\n","* Still work in progress\n","* get_ir3 function from TWristAR loader needs to be incorporated, currently this only loads a single file.\n"]},{"cell_type":"code","metadata":{"id":"q6H67o-YARCx","executionInfo":{"status":"ok","timestamp":1670956365115,"user_tz":360,"elapsed":810,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["import os\n","import shutil #https://docs.python.org/3/library/shutil.html\n","from shutil import unpack_archive # to unzip\n","#from shutil import make_archive # to create zip for storage\n","import requests #for downloading zip file\n","from scipy import io #for loadmat, matlab conversion\n","import time\n","import pandas as pd\n","import numpy as np\n","from numpy import savetxt\n","import matplotlib.pyplot as plt # for plotting - pandas uses matplotlib\n","from tabulate import tabulate # for g_verbose tables\n","from time import gmtime, strftime, localtime #for displaying Linux UTC timestamps in hh:mm:ss\n","from datetime import datetime\n","from datetime import timedelta\n","import urllib.request # to get files from web w/o !wget"],"execution_count":1,"outputs":[]},{"cell_type":"code","source":["my_dir = \".\" # replace with absolute path if desired\n","zip_baseURL = 'https://zenodo.org/record/6898244/files'\n","interactive = True # change to True if you want to run each cell function\n","# false with the ability to export to standalone .py not yet supported\n","global g_verbose # global, can be used in all functions without separate cfg.py\n","g_verbose = True\n","if interactive:\n","    print(\"work in progress\")\n","    #zip_ffname = os.path.join(my_dir,zip_fname)\n","    #zip_fullURL = zip_baseURL + zip_fname\n","    #working_dir = my_dir + str.split(zip_ffname,'.')[1] # get rid of .zip"],"metadata":{"id":"g2dGcRtEUMbZ","executionInfo":{"status":"ok","timestamp":1670956365118,"user_tz":360,"elapsed":19,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e020a169-3f2d-47bf-f9e9-2f47766fddc2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["work in progress\n"]}]},{"cell_type":"code","source":["interactive = False # skip if running Jupyter notebook version"],"metadata":{"id":"gK6fpqn877u3","executionInfo":{"status":"ok","timestamp":1670956365120,"user_tz":360,"elapsed":18,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def get_ue4w_zipfile(zip_fname):\n","    \"\"\"checks for local zipfile, if none downloads from zenodo repository\n","    after download will unzip the dataset into TWristAR directory.\n","    Assumes a global my_dir has been defined (default is my_dir = \".\")\n","    :return: nothing\"\"\"\n","    zip_fullURL = 'https://zenodo.org/record/6898244/files/' + zip_fname\n","    zip_ffname = os.path.join(my_dir,zip_fname)\n","    if (os.path.exists(zip_ffname)):\n","        print (\"Local zip file\", zip_ffname, \"found, skipping download\")\n","    else:\n","        print (\"Downloading\", zip_fullURL)\n","        urllib.request.urlretrieve(zip_fullURL, filename=zip_fname)\n","    return\n","if interactive:\n","    zip_fname = '1568381971_A01F11.zip'\n","    get_ue4w_zipfile(zip_fname = zip_fname)"],"metadata":{"id":"tlKEXl-BSrLO","executionInfo":{"status":"ok","timestamp":1670956365122,"user_tz":360,"elapsed":20,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"9oab3XMPgL8Z","executionInfo":{"status":"ok","timestamp":1670956365124,"user_tz":360,"elapsed":21,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["def unzip_e4_file(zip_ffname):\n","    \"\"\"checks for local copy, if none unzips the e4 zipfile in dir ffname\n","    Note:  the files themselves do not contain subject info and there are\n","    multiple files e.g. ACC.csv, BVP,csv etc, in each zipfile.\n","    It is very important to further process the files with <fname>_labels.csv\n","    :param zip_ffname: the path and filename of the zip file\n","    :param working_dir: local (colab) directory where csv files will be placed\n","    :return: nothing\"\"\"\n","    working_dir = my_dir + str.split(zip_ffname,'.')[1] # get rid of .zip\n","    if (os.path.isdir(working_dir)):\n","        print(\"Skipping Unzip - Found existing directory\", working_dir)\n","        return\n","    else:\n","        print(\"Unzipping e4 file in\", working_dir)\n","        if (os.path.exists(zip_ffname)):\n","            shutil.unpack_archive(zip_ffname,working_dir,'zip')\n","        else:\n","            print(\"Error: \", zip_ffname, \" not found, exiting\")\n","            return\n","if interactive:\n","    zip_ffname = os.path.join(my_dir,zip_fname)\n","    unzip_e4_file(zip_ffname)"],"execution_count":5,"outputs":[]},{"cell_type":"code","source":["interactive = False"],"metadata":{"id":"NUWzO-Zmto8R","executionInfo":{"status":"ok","timestamp":1670956365294,"user_tz":360,"elapsed":191,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"lisSuCzRcKfC","executionInfo":{"status":"ok","timestamp":1670956365296,"user_tz":360,"elapsed":15,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["def df_from_e4_csv (ffname,col_labels):\n","    \"\"\"\"reads e4 ACC, BVP, EDA, and TEMP(erature) csv files, uses start time and\n","    sample rate to create time indexed pandas dataframe with columns.  \n","    Note the other e4 files have different format and must be read seperately. \n","    :param ffname:  full filename e.g./content/temp/ACC.csv\n","    :col_labels: list of colums in csv - varies by type ['accel_x','accel_y...]\n","    :returns df: time indexed dataframe\"\"\"\n","\n","    df = pd.read_csv(ffname, header=None)\n","    start_time = df.iloc[0,0].astype('int64') # first line in e4 csv\n","    sample_freq = df.iloc[1,0].astype('int64') # second line in e4 csv\n","    df = df.drop(df.index[[0,1]]) # drop 1st two rows, index is now off by 2\n","    # Make the index datetime first so code can be used for other data types\n","    # Having the index as datetime is required for pandas resampling\n","    # The start_time from the e4 csv file is forced to int64 which represents the\n","    # number of nanoseconds since January 1, 1970, 00:00:00 (UTC)\n","    # This is tricky - if float representation the join function may not work\n","    # properly later since the indexes must match exactly.\n","    # UTC_time is computed for each row, then made into required datetime format\n","    # that pandas will accept as an index\n","    df['UTC_time'] = (df.index-2)/sample_freq + start_time\n","    end_time = df['UTC_time'].iloc[-1]\n","    if g_verbose:\n","        print(ffname, \"Sample frequency = \", sample_freq, \" Hz\")\n","        #show time in day month format, assumes same timezone\n","        print(\"File start time = \", strftime(\"%a, %d %b %Y %H:%M:%S\", localtime(start_time)))  \n","        print(\"File end time   = \",strftime(\"%a, %d %b %Y %H:%M:%S\", localtime(end_time)))\n","    #df = df.astype({'UTC_time': 'int64'}) # change future index from float64 to int64\n","    # this causes issues when trying to synch across sensors, if float then\n","    # some amount of error will be introduced.   May need to move earlier.\n","    df['datetime'] = pd.to_datetime(df['UTC_time'], unit='s')\n","    df.set_index('datetime',inplace=True)\n","    df = df.drop('UTC_time', axis=1)\n","    df.columns = col_labels\n","    return df\n","if interactive:\n","    # Note: IBI.csv is the inter-beat interval, a calculated value with a \n","    # different format.  HR.csv is also calculated from BVP but format is same.\n","    working_dir = '1568381971_A01F11' # by zipfile name\n","    ffname = working_dir + '/ACC.csv'\n","    col_labels = ['accel_x', 'accel_y', 'accel_z']\n","    ir1_acc_df = df_from_e4_csv(ffname, col_labels)\n","    print(\"ACC dataframe shape\", ir1_acc_df.shape)\n","    display(ir1_acc_df.head())\n","\n","    ffname = working_dir + '/BVP.csv'\n","    col_labels = ['bvp']\n","    ir1_bvp_df = df_from_e4_csv(ffname, col_labels)\n","    print(\"BVP dataframe shape\", ir1_bvp_df.shape)\n","    display(ir1_bvp_df.head())\n","\n","    ffname = working_dir + '/EDA.csv'\n","    col_labels = ['eda']\n","    ir1_eda_df = df_from_e4_csv(ffname, col_labels)\n","    print(\"EDA dataframe shape\", ir1_eda_df.shape)\n","    display(ir1_eda_df.head())\n","\n","    ffname = working_dir + '/TEMP.csv'\n","    col_labels = ['p_temp']\n","    ir1_temp_df = df_from_e4_csv(ffname, col_labels)\n","    print(\"Temp dataframe shape\", ir1_temp_df.shape)\n","    display(ir1_temp_df.head())"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"87sX9GDMdJcO","executionInfo":{"status":"ok","timestamp":1670956365298,"user_tz":360,"elapsed":15,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["def process_e4_accel(df):\n","    \"\"\"converts component accel into g and adds accel_ttl column\n","    per info.txt range is [-2g, 2g] and unit in this file is 1/64g.\n","    \"\"\"\n","    df['accel_x'] = df['accel_x']/64\n","    df['accel_y'] = df['accel_y']/64\n","    df['accel_z'] = df['accel_z']/64\n","    df_sqd = df.pow(2)[['accel_x', 'accel_y', 'accel_z']] #square each accel\n","    df_sum = df_sqd.sum(axis=1) #add sum of squares, new 1 col df\n","    df.loc[:,'accel_ttl'] = df_sum.pow(0.5)-1  # sqrt and remove 1g due to gravity\n","    del df_sqd, df_sum\n","    return df\n","if interactive:\n","    ir1_acc_df = process_e4_accel(ir1_acc_df)\n","    display(ir1_acc_df.head())"],"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def get_ir1_from_e4_dir(working_dir):\n","    \"\"\"processes the four e4 sensor files into a single dataframe that\n","    is datetime indexed at 32Hz. Labeled columns are channels\"\"\"\n","    # Note: IBI.csv is the inter-beat interval, a calculated value with a \n","    # different format.  HR.csv is also calculated from BVP but format is same.\n","    ffname = working_dir + '/ACC.csv'\n","    col_labels = ['accel_x', 'accel_y', 'accel_z']\n","    ir1_acc_df = df_from_e4_csv(ffname, col_labels)\n","    ir1_acc_df = process_e4_accel(ir1_acc_df)\n","\n","    ffname = working_dir + '/BVP.csv'\n","    col_labels = ['bvp']\n","    ir1_bvp_df = df_from_e4_csv(ffname, col_labels)\n","\n","    ffname = working_dir + '/EDA.csv'\n","    col_labels = ['eda']\n","    ir1_eda_df = df_from_e4_csv(ffname, col_labels)\n","\n","    ffname = working_dir + '/TEMP.csv'\n","    col_labels = ['p_temp']\n","    ir1_ptemp_df = df_from_e4_csv(ffname, col_labels)\n","\n","    ir1_df = ir1_acc_df.join(ir1_bvp_df, how=\"inner\") # this drops bvp to 32Hz\n","    ir1_df = ir1_df.join(ir1_eda_df, how=\"outer\") # stays at 32Hz, eda fill NaN\n","    ir1_df = ir1_df.join(ir1_ptemp_df, how=\"outer\") # stays at 32Hz, p_temp fill NaN\n","    ir1_df = ir1_df.interpolate() # default is linear interpolation\n","    ir1_df = ir1_df.astype('float32') # no need for 64 precision with these sensors\n","    if g_verbose:\n","        print(\"IR1 full dataframe shape\",ir1_df.shape)\n","        #print(ir1_df.head(10))\n","    return ir1_df\n","if interactive:\n","    ir1_df = get_ir1_from_e4_dir(working_dir)\n","    display(ir1_df.head(10))"],"metadata":{"id":"Ax17Aew_zTUu","executionInfo":{"status":"ok","timestamp":1670956365299,"user_tz":360,"elapsed":16,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["if interactive:\n","    y1 = 1000 # starting y value (row #)\n","    y2 = 2000 # ending, plotting the whole dataframe is too much.\n","    ir1_df.iloc[499:1999].plot(subplots=True, figsize=(20, 10)) # yay Pandas"],"metadata":{"id":"P0oiv5U6rCVm","executionInfo":{"status":"ok","timestamp":1670956365489,"user_tz":360,"elapsed":206,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZNmr-yPWcck","executionInfo":{"status":"ok","timestamp":1670956365490,"user_tz":360,"elapsed":24,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["def show_tag_time(tag_ffname):\n","    \"\"\"utility prints time marks from tags.csv to help with video sync \n","    and labeling.   When this is run in colab it seems to be GMT regardless\n","    of timezone settings.\"\n","    :param tag_ffname: file to be processed e.g. /content/temp/tags.csv'\n","    :return: nothing\"\"\"\n","    try: \n","        df_temp = pd.read_csv(tag_ffname, header=None)\n","    except:\n","        print(\"There are no tag marks in this file\")\n","        return\n","    else:\n","        df_temp.columns = ['UTC_time']\n","        print (\"    UTC_time          Local Time\")\n","        for index, row in df_temp.iterrows():\n","            print(index, row['UTC_time'],\n","                strftime(\"%a, %d %b %Y %H:%M:%S\", localtime(row['UTC_time'])))\n","# https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior\n","# link to string formats for date and time\n","if interactive:\n","    print(\"Note: the tags for UE4W are not reliable for changes in activity\")\n","    tag_ffname = working_dir + '/tags.csv'\n","    show_tag_time(tag_ffname)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttKS9Ox6JSed","executionInfo":{"status":"ok","timestamp":1670956365493,"user_tz":360,"elapsed":25,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["def label_unlabeled_df (df, label = 'unk', sub = 0):\n","    \"\"\"adds placeholder activity label and subject number columns to the\n","    dataframe.   This version for compatiblity only since it is unlabeled.\n","    :param df : time indexed dataframe from df_from_e4_csv method\n","    :label(str) : the label that will be applied to all rows\n","    :sub(int) : the sub number that will be applied to all rows\n","    :return : a dataframe with label and subject columns added\"\"\"\n","    df['label']= label # add column with safe value for labels\n","    df['sub'] = sub\n","    return df\n","if interactive:\n","    print(\"Adding placeholder label and sub info\")\n","    ir1_df = label_unlabeled_df(ir1_df)\n","    display(ir1_df[5000:5005]) # head is meaningless since start is undefined"],"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def get_ir2_from_ir1(df, time_steps, stride):\n","    \"\"\"slice the IR1 dataframe into sliding window segments of\n","    time_steps length and return X, y, sub ndarrays.\n","    If stride = time_steps there is no overlap of the sliding window.\n","    This version does not use append, better for RAM\n","    df: pandas datetime indexed dataframe columns - channel(s), label, sub\n","    time_steps: number of samples in window, will discard a partial final window\n","    stride:  how far to move window, no overlap if equal to time_steps.\n","    \"\"\"    \n","    # this was copied from SHL with improved memory capabilities\n","    # the channel list is in dataframe but not in the numpy arrays\n","    channel_list = list(df.columns)\n","    channel_list.remove('label') # need to make sure this is defined for IR1\n","    channel_list.remove('sub') # ditto - should probably add a check\n","    if g_verbose:\n","        print('Channels in X:',channel_list)\n","    X = df[channel_list].to_numpy(dtype = 'float32')\n","    y = df['label'].to_numpy(dtype='<U10')\n","    sub = df['sub'].to_numpy(dtype = 'int8')\n","    if g_verbose:\n","        print('X,y,sub array shapes before sliding window', X.shape, y.shape, sub.shape)\n","    #https://numpy.org/devdocs/reference/generated/numpy.lib.stride_tricks.sliding_window_view.html\n","    shapex = (time_steps,X.shape[1]) # samples (rows to include) and n-dim of original (all channels)\n","    shapey = (time_steps,) # samples (rows to include) and only one column\n","    shapesub = (time_steps,) # samples (rows to include) and only one column\n","    X = np.lib.stride_tricks.sliding_window_view(X, shapex)[::stride, :]\n","    X = X[:,0,:,:] # I admit I don't understand why this dimension appears...\n","    y = np.lib.stride_tricks.sliding_window_view(y, shapey)[::stride, :]\n","    sub = np.lib.stride_tricks.sliding_window_view(sub, shapesub)[::stride, :]\n","    # this was part of the clean function - rest is not needed for unlabeled\n","    y = y[:,0] # collapse columns\n","    y = y[np.newaxis].T  # convert to single column array\n","    sub = sub[:,0] # repeat for sub array\n","    sub = sub[np.newaxis].T\n","    if g_verbose:\n","        print('X,y,sub array shapes after sliding window', X.shape, y.shape, sub.shape)\n","    return X, y, sub, channel_list\n","if interactive:\n","    my_X, my_y, my_sub, all_channel_list = get_ir2_from_ir1(ir1_df, 96, 96)\n","    headers = (\"array\",\"shape\", \"object type\", \"data type\")\n","    mydata = [(\"my_X:\", my_X.shape, type(my_X), my_X.dtype),\n","            (\"my_y:\", my_y.shape ,type(my_y), my_y.dtype),\n","            (\"my_sub:\", my_sub.shape, type(my_sub), my_sub.dtype)]\n","    print(\"IR2 array info\")\n","    print(tabulate(mydata, headers=headers))\n","    print(\"Returned all_channel_list\", all_channel_list)"],"metadata":{"id":"8tzvWPWkYjJq","executionInfo":{"status":"ok","timestamp":1670956365494,"user_tz":360,"elapsed":25,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def limit_channel_ir3(ir3_X, \n","                      all_channel_list,# = ['accel_x', 'accel_y', 'accel_z', 'accel_ttl', 'bvp', 'eda', 'p_temp'],\n","                      keep_channel_list):# = ['accel_ttl','bvp', 'eda', 'p_temp']):\n","    \"\"\"Pass the full ir3_X array with all channels, the stored all_channel_list\n","    that was extracted from the ir1 dataframe column names, and a \n","    keep_channel_list.  Matching channels will be kept, all others dropped.\n","    This would have been much easier at IR1 but that would precluded channel \n","    experiments and by channel feature representations.\n","    This is really new code, I'm leaving in some commented statements for now\"\"\"\n","    ch_idx = []\n","    # should add check here for channels not in list\n","    for i in keep_channel_list:\n","        ch_idx.append(all_channel_list.index(i)) \n","    if g_verbose:\n","        print(\"Keeping X columns at index\", ch_idx)\n","    new_X = ir3_X[:,:,ch_idx]\n","    return new_X\n","if interactive:\n","    print(\"all_channel_list\", all_channel_list)\n","    print(\"starting X shape\", my_X.shape)\n","    print(\"first row\", my_X[0,0,:])\n","    my_new_X = limit_channel_ir3(my_X, all_channel_list = all_channel_list,\n","                                 keep_channel_list = ['accel_ttl','p_temp'])\n","    print(\"ending X shape\", my_new_X.shape)\n","    print(\"first row\", my_new_X[0,0,:])"],"metadata":{"id":"c1WYWW5jzf2-","executionInfo":{"status":"ok","timestamp":1670956365497,"user_tz":360,"elapsed":27,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def ue4w_load_dataset(\n","    zip_flist = ['1568381971_A01F11.zip','1568436702_A01F11.zip','1568636849_A01F11.zip'],\n","    verbose = False,\n","    keep_channel_list = ['accel_ttl','bvp', 'eda', 'p_temp'],\n","    return_info_dict = False # return dict of meta info along with ndarrays\n","    ):\n","    global g_verbose\n","    g_verbose = verbose\n","    print(\"Iterating through\", len(zip_flist), \"files in ue4w dataset\")\n","    # the hard coded 96 and 7 need to be fixed for other sample rates, channels\n","    ir3_X = np.zeros(shape=(1,96,len(keep_channel_list)), dtype = 'float32')\n","    ir3_y = np.full(shape=(1,1), fill_value='n/a',dtype='<U10') # unicode 10 char\n","    ir3_sub = np.zeros(shape=(1,1),dtype=np.uint8) # one subject number per entry\n","    for zip_fname in zip_flist:\n","        zip_ffname = os.path.join(my_dir,zip_fname)\n","        get_ue4w_zipfile(zip_fname)\n","        working_dir = my_dir + str.split(zip_ffname,'.')[1] # get rid of .zip\n","        unzip_e4_file(zip_ffname)\n","        print('Processing ', zip_ffname)\n","        my_df = get_ir1_from_e4_dir(working_dir)\n","        my_df = label_unlabeled_df(my_df)\n","        if g_verbose:\n","            print(my_df.head())\n","        my_X, y, sub, all_channel_list = get_ir2_from_ir1(my_df, 96, 96)\n","        my_X = limit_channel_ir3(my_X, all_channel_list= all_channel_list,\n","                              keep_channel_list = keep_channel_list) # default is to drop component accel\n","        ir3_X = np.vstack([ir3_X, my_X])\n","        ir3_y = np.vstack([ir3_y, y])\n","        ir3_sub = np.vstack([ir3_sub, sub])\n","    X = np.delete(ir3_X, (0), axis=0) \n","    y = np.delete(ir3_y, (0), axis=0) \n","    sub = np.delete(ir3_sub, (0), axis=0)\n","    sub = sub.astype(np.uint8) # convert from float to int\n","    return X, y, sub, keep_channel_list"],"metadata":{"id":"0Sh26Gt1qh0x","executionInfo":{"status":"ok","timestamp":1670956365499,"user_tz":360,"elapsed":29,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6x8jy4IRV8xD"},"source":["# Main Function"]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    # Test the defaults\n","    X, y, sub, ch_list = ue4w_load_dataset()\n","    headers = (\"Array\",\"shape\", \"data type\")\n","    mydata = [(\"X:\", X.shape, X.dtype),\n","            (\"y:\", y.shape, y.dtype),\n","            (\"sub:\", sub.shape, sub.dtype)]\n","    print(\"\\n\",tabulate(mydata, headers=headers))\n","    print(\"Channels:\", ch_list)\n","\n","    # Test for single subject with only accel X shape should be (11926, 96, 1)\n","    X, y, sub, ch_list = ue4w_load_dataset(zip_flist = ['1568381971_A01F11.zip'],\n","                                           keep_channel_list = ['accel_ttl'])\n","    headers = (\"Array\",\"shape\", \"data type\")\n","    mydata = [(\"X:\", X.shape, X.dtype),\n","            (\"y:\", y.shape, y.dtype),\n","            (\"sub:\", sub.shape, sub.dtype)]\n","    print(\"\\n\",tabulate(mydata, headers=headers))\n","    print(\"Channels:\", ch_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYQ6VyWw97tx","executionInfo":{"status":"ok","timestamp":1670956420749,"user_tz":360,"elapsed":55279,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"outputId":"df1c04cb-a3eb-488f-fe6d-0b7300a9501c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Iterating through 3 files in ue4w dataset\n","Downloading https://zenodo.org/record/6898244/files/1568381971_A01F11.zip\n","Unzipping e4 file in ./1568381971_A01F11\n","Processing  ./1568381971_A01F11.zip\n","Downloading https://zenodo.org/record/6898244/files/1568436702_A01F11.zip\n","Unzipping e4 file in ./1568436702_A01F11\n","Processing  ./1568436702_A01F11.zip\n","Downloading https://zenodo.org/record/6898244/files/1568636849_A01F11.zip\n","Unzipping e4 file in ./1568636849_A01F11\n","Processing  ./1568636849_A01F11.zip\n","\n"," Array    shape           data type\n","-------  --------------  -----------\n","X:       (33523, 96, 4)  float32\n","y:       (33523, 1)      <U10\n","sub:     (33523, 1)      uint8\n","Channels: ['accel_ttl', 'bvp', 'eda', 'p_temp']\n","Iterating through 1 files in ue4w dataset\n","Local zip file ./1568381971_A01F11.zip found, skipping download\n","Skipping Unzip - Found existing directory ./1568381971_A01F11\n","Processing  ./1568381971_A01F11.zip\n","\n"," Array    shape           data type\n","-------  --------------  -----------\n","X:       (11926, 96, 1)  float32\n","y:       (11926, 1)      <U10\n","sub:     (11926, 1)      uint8\n","Channels: ['accel_ttl']\n"]}]},{"cell_type":"code","source":["# run this cell to save the numpy arrays\n","if interactive:  \n","    readme = 'Unlabeled data from UE4W Repository, three files\\n'\n","    readme += 'this version for fusion learned reps paper.\\n'\n","    readme += 'Lee Hinkle, IMICS lab, December 13, 2022\\n'\n","    readme += ' Array    shape           data type\\n'\n","    readme += '        -------  --------------  -----------\\n'\n","    readme += 'X:       (33523, 96, 4)  float32\\n'\n","    readme += 'y:       (33523, 1)      <U10\\n'\n","    readme += 'sub:     (33523, 1)      uint8\\n'       \n","    readme += \"         ['accel_ttl', 'bvp', 'eda', 'p_temp']'\\n\"\n","\n","    with open(my_dir+'/README.txt', \"w\") as file_object:\n","        file_object.write(readme)\n","    np.save(my_dir + '/'+'X.npy',X)\n","    np.save(my_dir + '/'+'y.npy',y)\n","    np.save(my_dir + '/'+'sub.npy',sub)\n"],"metadata":{"id":"urcThXb92bpl","executionInfo":{"status":"ok","timestamp":1670956420750,"user_tz":360,"elapsed":20,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Example code that can be used to call this function when saved as .py"],"metadata":{"id":"2gXZ3BFL04gJ"}},{"cell_type":"code","source":["# def get_ue4w_loader():\n","#     \"\"\"checks for local file, if none downloads from IMICS repository.\n","#     Assumes a global my_dir has been defined (default is my_dir = \".\")\n","#     :return: nothing\"\"\"\n","#     ffname = os.path.join(my_dir,'ue4w_load_dataset.py')\n","#     if (os.path.exists(ffname)):\n","#         print (\"Local twristar_load_dataset.py found, skipping download\")\n","#     else:\n","#         print(\"Downloading twristar_load_dataset.py from IMICS git repo\")\n","#         urllib.request.urlretrieve(\"https://raw.githubusercontent.com/imics-lab/load_data_time_series/main/HAR/e4_wristband_Nov2019/ue4w_load_dataset.py\", filename=\"ue4w_load_dataset.py\")\n","# if interactive:\n","#     get_ue4w_loader()"],"metadata":{"id":"yv9zW2d0XsB6","executionInfo":{"status":"ok","timestamp":1670956420750,"user_tz":360,"elapsed":19,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# from ue4w_load_dataset import ue4w_load_dataset\n","# # kludge for now - names should be derived from returned info from loader\n","# t_names = ['Downstairs', 'Jogging', 'Sitting', 'Standing', 'Upstairs', 'Walking']\n","# channel_list = ['accel_ttl','bvp','eda', 'p_temp'] # all channels to be used\n","#     x_train, y_train, x_valid, y_valid, x_test, y_test, log_info \\\n","#                                 = twristar_load_dataset(\n","#                                     incl_val_group = True,\n","#                                     keep_channel_list = ch_list,\n","#                                     return_info_dict = True)\n","#     if verbose:\n","#         print (log_info)"],"metadata":{"id":"e0ELDahbEFXz","executionInfo":{"status":"ok","timestamp":1670956420751,"user_tz":360,"elapsed":20,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":19,"outputs":[]}]}