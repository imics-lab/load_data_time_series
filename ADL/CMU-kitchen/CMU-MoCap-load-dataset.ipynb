{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1hyDKo_DVhEMUbYvLNOwOKl38dHH3q1OT","timestamp":1676585773621},{"file_id":"1EV-4h9GXe5FGxCYhlC-Z50ZTJq_tmSnk","timestamp":1663265169606},{"file_id":"1WbviRoNfMEZwPiA0Jm0FruV9l8tODu_e","timestamp":1656703965031},{"file_id":"1RkiXI3GhB-rNtyUp_VYw05xiiuD_oDFA","timestamp":1612028534003}],"machine_shape":"hm","authorship_tag":"ABX9TyP7JEeBky4uGdvDc42oh3rw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"Khc4g511HMYk"},"source":["#CMU-MoCap-load-dataset.ipynb\n","This is a loader for the CMU grand challenge dataset with motion capture for subjects making several recipes.\n","\n","The data used is obtained from kitchen.cs.cmu.edu and the data collection was funded in part by the National Science Foundation under Grant No. EEEC-0540865.\n","\n","http://kitchen.cs.cmu.edu/main.php\n","\n","If you use this dataset in your work please follow the dataset authors' citation request [here](https://www.ri.cmu.edu/publications/guide-to-the-carnegie-mellon-university-multimodal-activity-cmu-mmac-database/).\n","\n","This is work in progress and frequently updated, please check the repository at our [IMICS Lab Github repository](https://github.com/imics-lab/load_data_time_series) for the latest.  Much appreciation to Vangelis Metsis and Alex Katrompas for the [initial loader](https://git.txstate.edu/imics-lab/tattend/tree/main/scripts) from which multiple methods have been derived.\n","\n","<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n","\n","[Lee B. Hinkle](https://userweb.cs.txstate.edu/~lbh31/), Texas State University, [IMICS Lab](https://imics.wp.txstate.edu/)  \n","TODO:\n","* A lot.  This version is early work.\n"]},{"cell_type":"code","metadata":{"id":"q6H67o-YARCx","executionInfo":{"status":"ok","timestamp":1683595936915,"user_tz":300,"elapsed":566,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["import os\n","import shutil #https://docs.python.org/3/library/shutil.html\n","from shutil import unpack_archive # to unzip\n","import time\n","#import csv # probably not needed once download processes zip\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from numpy import savetxt\n","#from tabulate import tabulate # for verbose tables, showing data\n","from tensorflow.keras.utils import to_categorical # for one-hot encoding\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","import matplotlib.pyplot as plt # for plotting - pandas uses matplotlib\n","from time import gmtime, strftime, localtime #for displaying Linux UTC timestamps in hh:mm:ss\n","from datetime import datetime, date, timedelta\n","import urllib.request # to get files from web w/o !wget\n","import zipfile"],"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1683595937167,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"},"user_tz":300},"id":"gajdw42Dt_yO"},"outputs":[],"source":["def get_web_file(fname, url):\n","    \"\"\"checks for local file, if none downloads from URL.    \n","    :return: nothing\"\"\"\n","    if (os.path.exists(fname)):\n","        print (\"Local\",fname, \"found, skipping download\")\n","    else:\n","        print(\"Downloading\",fname, \"from\", url)\n","        urllib.request.urlretrieve(url, filename=fname)"]},{"cell_type":"markdown","source":["# Load shared transform (xform) functions and utils"],"metadata":{"id":"GZ3Jm4r354nl"}},{"cell_type":"code","source":["try:\n","    import load_data_transforms as xform\n","except:\n","    get_web_file(fname = 'load_data_transforms.py', url = 'https://raw.githubusercontent.com/imics-lab/load_data_time_series/main/load_data_transforms.py')\n","    import load_data_transforms as xform\n","\n","try:\n","    import load_data_utils as utils  \n","except:\n","    get_web_file(fname = 'load_data_utils.py', url = 'https://raw.githubusercontent.com/imics-lab/load_data_time_series/main/load_data_utils.py')\n","    import load_data_utils as utils"],"metadata":{"id":"t7qLPe1l4h2V","executionInfo":{"status":"ok","timestamp":1683595937169,"user_tz":300,"elapsed":20,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Setup environment and dataset parameters"],"metadata":{"id":"w19hyG9gLubD"}},{"cell_type":"code","metadata":{"id":"w4GYTFUJK3Yy","executionInfo":{"status":"ok","timestamp":1683595937170,"user_tz":300,"elapsed":21,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["# environment and execution parameters\n","my_dir = '.' # replace with absolute path if desired\n","ir1_dir = 'cmu_ir1' # this is where the raw data IR1s will be stored\n","#working_dir = 'psg_temp'\n","# if not os.path.exists(working_dir):\n","#     os.mkdir(working_dir)\n","interactive = True # for exploring data and functions interactively\n","verbose = True\n","\n","# dataset parameters\n","all_channel_list = [] # this will get populated from the IR1 dataframe column names\n","xform.time_steps = 500 # IR1 dataframes are set to 100Hz\n","xform.stride = 500 # how far to move for next window, if = times_steps no overlap\n","# The label_map_<dataset> contains a mapping from strings to ints for all\n","# possible labels in the entire dataset.   This allows for predictable conversion\n","# regardless of the slices.\n","label_map_psg = dict()\n","\n","# setup a global readme so various methods can append info as needed\n","readme = 'This readme auto-generated by CMU-MoCap_load_dataset.ipynb\\n'\n","readme += 'Executed on '\n","today = date.today()\n","readme += today.strftime(\"%B %d, %Y\") + \"\\n\"\n","readme += 'ref: https://github.com/imics-lab/load_data_time_series \\n'"],"execution_count":16,"outputs":[]},{"cell_type":"code","source":["interactive = False # skip this cell, runs automatically for .py version"],"metadata":{"id":"g-OgF996EjMj","executionInfo":{"status":"ok","timestamp":1683595937170,"user_tz":300,"elapsed":20,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# CMU kitchen specific functions\n","Much appreciation to Vangelis Metsis and Alex Katrompas for the [initial loader](https://git.txstate.edu/imics-lab/tattend/tree/main/scripts) from which multiple methods have been derived.\n"],"metadata":{"id":"IieeZ0HkJP6h"}},{"cell_type":"code","source":["df_labels = pd.DataFrame() # workaround to get a global\n","# Assign labels to each frame in the time synchronization data\n","def assign_label(frame_number, offset):\n","    for _, row in df_labels.iterrows():\n","        if row['start_frame'] <= frame_number - (offset - 1) <= row['end_frame']:\n","            return row['label']\n","    return 'unknown'\n","\n","# Function to process the IMU data file\n","def process_data_file(file_path, archive):\n","    with archive.open(file_path) as f:\n","        # Get the sensor_ID from the first line of the file, e.g. \"sensor_ID\t2794\"\n","        sensor_id = f.readline().decode('utf-8').split('\\t')[1].strip()\n","\n","        # Read the rest of the file into a Pandas DataFrame\n","        df = pd.read_csv(f, delim_whitespace=True)\n","\n","    # Check if 'Count' column contains any string values\n","    if df['Count'].apply(lambda x: isinstance(x, str)).any():\n","        # Drop rows containing \"ERROR_1--TIMEOUT\" in the Count column\n","        df = df[~df['Count'].str.contains('ERROR')]\n","\n","    # Convert SysTime to datetime object\n","    df['system_time'] = df['SysTime'].str.replace('_', ':')\n","    df['system_time'] = pd.to_datetime(df['system_time'], format='%H:%M:%S:%f')\n","    df.drop('SysTime', axis=1, inplace=True)\n","\n","    # Remove sensor_ID row and reset the index\n","    # this next line is commented out, it shouldn't be here,\n","    # tested by vangelis, TODO test it more\n","    #df = df.drop(df.index[0]).reset_index(drop=True)\n","\n","    # Drop the Count column\n","    df = df.drop('Count', axis=1)\n","\n","    # Add sensor_ID as prefix to column names\n","    df.columns = [f'{sensor_id}_{col}' for col in df.columns]\n","\n","    return df, sensor_id\n","\n","# Function to merge two dataframes based on the nearest timestamp\n","def merge_dataframes(df1, df2):\n","    # Ensure system_time column in df1 is a datetime object\n","    if df1['system_time'].dtype != 'datetime64[ns]':\n","        df1['system_time'] = pd.to_datetime(df1['system_time'])\n","\n","    # Find the system_time column in df2 and convert it to a datetime object\n","    for col in df2.columns:\n","        if col.endswith('_system_time'):\n","            if df2[col].dtype != 'datetime64[ns]':\n","                df2[col] = pd.to_datetime(df2[col])\n","            system_time_col = col\n","\n","    # Sort df1 and df2 on the system_time columns\n","    df1 = df1.sort_values('system_time')\n","    df2 = df2.sort_values(system_time_col)\n","\n","    # Merge the dataframes based on the nearest timestamp\n","    merged_df = pd.merge_asof(df1, df2, left_on='system_time', right_on=system_time_col, direction='nearest')\n","\n","    # Drop the system_time column from the second dataframe\n","    merged_df = merged_df.drop(columns=[system_time_col])\n","\n","    return merged_df"],"metadata":{"id":"Ec6wxus2hBRk","executionInfo":{"status":"ok","timestamp":1683595937171,"user_tz":300,"elapsed":20,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# define relative path\n","#RPATH = \"../data/kitchen/\"\n","RPATH = \"./\"\n","\n","# Create the brownie_imu_data directory if it doesn't exist\n","if not os.path.exists(RPATH + 'brownie_imu_data'):\n","    os.makedirs(RPATH + 'brownie_imu_data')\n","\n","# Define the subject IDs and start frames\n","subjects = {'S07': 508,\n","            'S08': 300,\n","            'S09':226,\n","            'S12':400,\n","            'S13':290,\n","            'S14':386,\n","            'S16':168,\n","            'S17':236,\n","            'S18':316,\n","            'S19':354,\n","            'S20':212,\n","            'S22':262,\n","            'S24':360}\n","if interactive:\n","    print(\"All subject and offsets:\", subjects)\n","    print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_vMNg-mhO5a","executionInfo":{"status":"ok","timestamp":1683595937171,"user_tz":300,"elapsed":20,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"outputId":"2a36574e-26f5-4cd3-99a7-12b20ba095ea"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["All subject and offsets: {'S07': 508, 'S08': 300, 'S09': 226, 'S12': 400, 'S13': 290, 'S14': 386, 'S16': 168, 'S17': 236, 'S18': 316, 'S19': 354, 'S20': 212, 'S22': 262, 'S24': 360}\n","\n"]}]},{"cell_type":"code","source":["#for key in subjects:\n","def get_cmu_imu_df(sub_key = 'S07'):\n","    subject_id = sub_key\n","    subject_starting_frame = subjects[sub_key]\n","    if verbose:\n","        print(\"subject_id:\", subject_id)\n","        print(\"subject_starting_frame\", subject_starting_frame)\n","        print()\n","\n","    # Define file paths\n","    video_zip_url = f'http://kitchen.cs.cmu.edu/Main/{subject_id}_Brownie_Video.zip'\n","    video_zip_file = f'{RPATH}brownie_imu_data/{subject_id}_Brownie_Video.zip'\n","    imu_zip_url = f'http://kitchen.cs.cmu.edu/Main/{subject_id}_Brownie_3DMGX1.zip'\n","    imu_zip_file = f'{RPATH}brownie_imu_data/{subject_id}_Brownie_3DMGX1.zip'\n","    annotation_zip_url = f'http://www.cs.cmu.edu/~espriggs/cmu-mmac/annotations/files/{subject_id}_Brownie.zip'\n","    annotation_zip_file = f'{RPATH}brownie_imu_data/{subject_id}_Brownie.zip'\n","\n","    # Download the video data file if it hasn't been downloaded already\n","    if not os.path.exists(video_zip_file):\n","        if verbose:\n","            print(f'Downloading {video_zip_url}...')\n","        urllib.request.urlretrieve(video_zip_url, video_zip_file)\n","        if verbose:\n","            print(f'Saved {video_zip_file} to brownie_imu_data.')\n","\n","    # Load the time synchronization data from the video data file into a Pandas DataFrame\n","    with zipfile.ZipFile(video_zip_file) as zipf:\n","        with zipf.open(f'STime7150991-time-synch.txt') as file:\n","            df_time_sync = pd.read_csv(file, sep=' ', header=None, usecols=[0, 4], names=['frame_number', 'system_time'])\n","\n","    df_time_sync['frame_number'] = df_time_sync['frame_number'].str.replace('Frame:', '')\n","    df_time_sync['frame_number'] = df_time_sync['frame_number'].astype(int)\n","    if verbose:\n","        display(df_time_sync.head())\n","\n","    # Download the 5 wired IMU data files if they haven't been downloaded already\n","    if not os.path.exists(imu_zip_file):\n","        if verbose:\n","            print(f'Downloading {imu_zip_url}...')\n","        urllib.request.urlretrieve(imu_zip_url, imu_zip_file)\n","        if verbose:\n","            print(f'Saved {imu_zip_file} to brownie_imu_data.')\n","\n","    # Download the annotation file if it hasn't been downloaded already\n","    if not os.path.exists(annotation_zip_file):\n","        if verbose:\n","            print(f'Downloading {annotation_zip_url}...')\n","        urllib.request.urlretrieve(annotation_zip_url, annotation_zip_file)\n","        if verbose:\n","            print(f'Saved {annotation_zip_file} to brownie_imu_data.')\n","\n","    # Load the annotation data from the annotation file into a Pandas DataFrame\n","    with zipfile.ZipFile(annotation_zip_file) as zipf:\n","        with zipf.open(f'{subject_id}_Brownie/labels.dat') as file:\n","            df_labels = pd.read_csv(file, sep=' ', names=['start_frame', 'end_frame', 'label'])\n","\n","    df_labels['start_frame'] = df_labels['start_frame'].astype(int)\n","    df_labels['end_frame'] = df_labels['end_frame'].astype(int)\n","    if verbose:\n","        print('df_labels.head()')\n","        display(df_labels.head())\n","\n","    df_time_sync['label'] = df_time_sync['frame_number'].apply(assign_label, offset=subject_starting_frame)\n","\n","    # Convert the system_time column to a datetime object\n","    df_time_sync['system_time'] = df_time_sync['system_time'].str.replace('_', ':')\n","    df_time_sync['system_time'] = pd.to_datetime(df_time_sync['system_time'], format='%H:%M:%S:%f')\n","    df_time_sync.head()\n","\n","    # Save df_time_sync to a CSV file (for visual inspection)\n","    time_sync_data_file = f'{RPATH}brownie_imu_data/{subject_id}_time_sync_data.csv'\n","    df_time_sync.to_csv(time_sync_data_file, index=False)\n","    if verbose:\n","        print(f'Saved {time_sync_data_file} to brownie_imu_data.')\n","\n","    # Open the zip file\n","    with zipfile.ZipFile(imu_zip_file, 'r') as archive:\n","        # Get the list of text files in the zip file\n","        file_paths = [file for file in archive.namelist() if file.endswith('.txt')]\n","\n","        df_main = df_time_sync\n","\n","        # Process each file in the zip file and merge it with df_main\n","        if verbose:\n","            print(f'Processing {len(file_paths)} files...')\n","        for file_path in file_paths:\n","            if verbose:\n","                print(f'Processing {file_path}...')\n","            df_temp, sensor_id = process_data_file(file_path, archive)\n","            df_main = merge_dataframes(df_main, df_temp)\n","    \n","    # Minor conversions to match IR1 format\n","    df_main.set_index('system_time',inplace=True) # make datetime indexed\n","    df_main.drop(['frame_number'], axis=1, inplace=True)\n","    \n","    # Add subject number to dataframe\n","    sub_num = int(sub_key[1:]) # get rid of leading S and make int\n","    df_main['sub'] = sub_num\n","    df_main = df_main.astype({\"sub\": np.int16}) # sub nums are higher than 255\n","\n","    # downsample 64-bit floats to 32-bit and force labels to categorical.\n","    # this reduces the size of the first dataframe from 345MB to 150MB.\n","    # this code originally pulled from latest TWRistAR loader\n","    # Select columns with 'float64' dtype  \n","    float64_cols = list(df_main.select_dtypes(include='float64'))\n","    if verbose:\n","        print(\"get_ir1_from_dir found these float64 cols - changing to float32\")\n","        print(float64_cols)\n","    # Next line gives a key length error - not sure why, and the loop works.\n","    # ir1_df[float64_cols] = ir1_df[float64_cols].astype('float32')\n","    for i in float64_cols:\n","        df_main[i] = df_main[i].astype('float32')\n","    # Explicitly type the label columns to category.\n","    df_main['label']=df_main['label'].astype('category')\n","    # Move the label to the end, right before sub, just for consistency\n","    df_main = df_main[[c for c in df_main if c not in ['label', 'sub']] \n","       + ['label', 'sub']]\n","    return df_main\n","\n","if interactive:\n","    df = get_cmu_imu_df()\n","    display(df.head())\n","    display(df.info())\n","\n","    # Save df_main to a CSV file\n","    # imu_data_file = f'{RPATH}brownie_imu_data/{subject_id}_imu_data.csv'\n","    # df_main.to_csv(imu_data_file, index=False)"],"metadata":{"id":"tUiMwh75mfE5","executionInfo":{"status":"ok","timestamp":1683595937171,"user_tz":300,"elapsed":18,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def get_cmu_mocap_ir1_dict():\n","    \"\"\"reads the CMU Motion Cap dataset brownie files and converts to an IR1\n","    dataframe.  The goal here is to capture and convert all raw data into\n","    a 2D dataframe of rows = datetime index of each sample, columns = {channels,\n","    label(s), subject_num}.  Additional methods may be used to drop channels,\n","    and convert the string labels to mapped ints prior to switch to ndarrays.\n","    Args:\n","    none but uses global scripted (boolean):\n","    Returns: a dict containing key = df_name and item = IR1 dataframes.\"\"\"\n","\n","    ir1_df_dict = dict() # an empty dictionary\n","    for key in subjects:\n","        ir1_fname = key+'_Brownie_3DMGX1'\n","        print('Processing',ir1_fname)\n","        df = get_cmu_imu_df(sub_key = key)\n","        ir1_df_dict[ir1_fname]=df\n","    return ir1_df_dict\n","if interactive:\n","    verbose = False\n","    ir1_dict = get_cmu_mocap_ir1_dict()\n","    print('IR1 dataframes:',ir1_dict.keys())\n","    for df_name, df in ir1_dict.items():\n","        display(df.head())\n","        break # just want one"],"metadata":{"id":"p_EmZhbavtzi","executionInfo":{"status":"ok","timestamp":1683595937172,"user_tz":300,"elapsed":18,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# No idea why this takes so long to plot with just 3 channels and 1K rows\n","# df[['2794_Accel_X','2794_Accel_Y','2794_Accel_Z']].iloc[999:1999].plot(subplots=True, figsize=(20, 10)) # yay Pandas"],"metadata":{"id":"6Z3YwKWU4k0t","executionInfo":{"status":"ok","timestamp":1683595937172,"user_tz":300,"elapsed":17,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["# Main is setup to be a demo and bit of unit test."],"metadata":{"id":"tncwIiZaB3j3"}},{"cell_type":"code","source":["verbose = False # otherwise a lot of output from main."],"metadata":{"id":"_vFw54Dwm59t","executionInfo":{"status":"ok","timestamp":1683595937172,"user_tz":300,"elapsed":17,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"MaT1dfqavvtk","colab":{"base_uri":"https://localhost:8080/","height":678},"executionInfo":{"status":"ok","timestamp":1683595968822,"user_tz":300,"elapsed":31667,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"outputId":"820ebc36-2dc4-463c-f973-f214a2816210"},"source":["if __name__ == \"__main__\":\n","    print(\"Get dictionary of IR1 dataframes, this takes ~15 minutes to run with downloads\")\n","    ir1_dict = get_cmu_mocap_ir1_dict()\n","    print('IR1 dataframes:',ir1_dict.keys())\n","    for df_name, df in ir1_dict.items():\n","        print(df.head())\n","        break # just want one\n"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Get dictionary of IR1 dataframes, this takes ~15 minutes to run\n","Processing S07_Brownie_3DMGX1\n","Processing S08_Brownie_3DMGX1\n","Processing S09_Brownie_3DMGX1\n","Processing S12_Brownie_3DMGX1\n","Processing S13_Brownie_3DMGX1\n","Processing S14_Brownie_3DMGX1\n","Processing S16_Brownie_3DMGX1\n","Processing S17_Brownie_3DMGX1\n","Processing S18_Brownie_3DMGX1\n","Processing S19_Brownie_3DMGX1\n","Processing S20_Brownie_3DMGX1\n","Processing S22_Brownie_3DMGX1\n","Processing S24_Brownie_3DMGX1\n","IR1 dataframes: dict_keys(['S07_Brownie_3DMGX1', 'S08_Brownie_3DMGX1', 'S09_Brownie_3DMGX1', 'S12_Brownie_3DMGX1', 'S13_Brownie_3DMGX1', 'S14_Brownie_3DMGX1', 'S16_Brownie_3DMGX1', 'S17_Brownie_3DMGX1', 'S18_Brownie_3DMGX1', 'S19_Brownie_3DMGX1', 'S20_Brownie_3DMGX1', 'S22_Brownie_3DMGX1', 'S24_Brownie_3DMGX1'])\n"]},{"output_type":"display_data","data":{"text/plain":["                            2794_Accel_X  2794_Accel_Y  2794_Accel_Z  \\\n","system_time                                                            \n","1900-01-01 16:31:02.317625      0.243538     -0.407819      0.843623   \n","1900-01-01 16:31:02.350957      0.243538     -0.407605      0.843623   \n","1900-01-01 16:31:02.384289      0.243538     -0.407819      0.843623   \n","1900-01-01 16:31:02.417621      0.243751     -0.407819      0.843410   \n","1900-01-01 16:31:02.450953      0.243965     -0.407178      0.843623   \n","\n","                            2794_Roll  2794_Pitch  2794_Yaw  2794_Mag_X  \\\n","system_time                                                               \n","1900-01-01 16:31:02.317625   0.013492   -0.003138  0.013179   -0.630127   \n","1900-01-01 16:31:02.350957   0.004393    0.012865 -0.007844   -0.630127   \n","1900-01-01 16:31:02.384289   0.005334   -0.005020 -0.001255   -0.630127   \n","1900-01-01 16:31:02.417621   0.013492   -0.003138 -0.003765   -0.630371   \n","1900-01-01 16:31:02.450953   0.001883   -0.011923 -0.008158   -0.630615   \n","\n","                            2794_Mag_Y  2794_Mag_Z  2795_Accel_X  ...  \\\n","system_time                                                       ...   \n","1900-01-01 16:31:02.317625    0.301392   -1.026489      0.942747  ...   \n","1900-01-01 16:31:02.350957    0.301147   -1.026489      0.943388  ...   \n","1900-01-01 16:31:02.384289    0.301270   -1.026611      0.944243  ...   \n","1900-01-01 16:31:02.417621    0.301392   -1.026367      0.945097  ...   \n","1900-01-01 16:31:02.450953    0.300537   -1.026489      0.945311  ...   \n","\n","                            3337_Accel_Y  3337_Accel_Z  3337_Roll  3337_Pitch  \\\n","system_time                                                                     \n","1900-01-01 16:31:02.317625      0.822474      0.552873  -0.005020    0.008158   \n","1900-01-01 16:31:02.350957      0.822474      0.552873   0.007531    0.010041   \n","1900-01-01 16:31:02.384289      0.822474      0.552660   0.005962    0.001255   \n","1900-01-01 16:31:02.417621      0.822474      0.552660   0.011610    0.002510   \n","1900-01-01 16:31:02.450953      0.822687      0.552446  -0.002824   -0.001883   \n","\n","                            3337_Yaw  3337_Mag_X  3337_Mag_Y  3337_Mag_Z  \\\n","system_time                                                                \n","1900-01-01 16:31:02.317625  0.004393   -0.350830   -0.963013   -0.650269   \n","1900-01-01 16:31:02.350957  0.001883   -0.350708   -0.963013   -0.650269   \n","1900-01-01 16:31:02.384289  0.011610   -0.350708   -0.963013   -0.650269   \n","1900-01-01 16:31:02.417621  0.000941   -0.350952   -0.963013   -0.650146   \n","1900-01-01 16:31:02.450953  0.010041   -0.351074   -0.963013   -0.650024   \n","\n","                              label  sub  \n","system_time                               \n","1900-01-01 16:31:02.317625  unknown    7  \n","1900-01-01 16:31:02.350957  unknown    7  \n","1900-01-01 16:31:02.384289  unknown    7  \n","1900-01-01 16:31:02.417621  unknown    7  \n","1900-01-01 16:31:02.450953  unknown    7  \n","\n","[5 rows x 47 columns]"],"text/html":["\n","  <div id=\"df-83ab4a3e-540a-4ee8-927e-9aa02ed36be6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2794_Accel_X</th>\n","      <th>2794_Accel_Y</th>\n","      <th>2794_Accel_Z</th>\n","      <th>2794_Roll</th>\n","      <th>2794_Pitch</th>\n","      <th>2794_Yaw</th>\n","      <th>2794_Mag_X</th>\n","      <th>2794_Mag_Y</th>\n","      <th>2794_Mag_Z</th>\n","      <th>2795_Accel_X</th>\n","      <th>...</th>\n","      <th>3337_Accel_Y</th>\n","      <th>3337_Accel_Z</th>\n","      <th>3337_Roll</th>\n","      <th>3337_Pitch</th>\n","      <th>3337_Yaw</th>\n","      <th>3337_Mag_X</th>\n","      <th>3337_Mag_Y</th>\n","      <th>3337_Mag_Z</th>\n","      <th>label</th>\n","      <th>sub</th>\n","    </tr>\n","    <tr>\n","      <th>system_time</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1900-01-01 16:31:02.317625</th>\n","      <td>0.243538</td>\n","      <td>-0.407819</td>\n","      <td>0.843623</td>\n","      <td>0.013492</td>\n","      <td>-0.003138</td>\n","      <td>0.013179</td>\n","      <td>-0.630127</td>\n","      <td>0.301392</td>\n","      <td>-1.026489</td>\n","      <td>0.942747</td>\n","      <td>...</td>\n","      <td>0.822474</td>\n","      <td>0.552873</td>\n","      <td>-0.005020</td>\n","      <td>0.008158</td>\n","      <td>0.004393</td>\n","      <td>-0.350830</td>\n","      <td>-0.963013</td>\n","      <td>-0.650269</td>\n","      <td>unknown</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>1900-01-01 16:31:02.350957</th>\n","      <td>0.243538</td>\n","      <td>-0.407605</td>\n","      <td>0.843623</td>\n","      <td>0.004393</td>\n","      <td>0.012865</td>\n","      <td>-0.007844</td>\n","      <td>-0.630127</td>\n","      <td>0.301147</td>\n","      <td>-1.026489</td>\n","      <td>0.943388</td>\n","      <td>...</td>\n","      <td>0.822474</td>\n","      <td>0.552873</td>\n","      <td>0.007531</td>\n","      <td>0.010041</td>\n","      <td>0.001883</td>\n","      <td>-0.350708</td>\n","      <td>-0.963013</td>\n","      <td>-0.650269</td>\n","      <td>unknown</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>1900-01-01 16:31:02.384289</th>\n","      <td>0.243538</td>\n","      <td>-0.407819</td>\n","      <td>0.843623</td>\n","      <td>0.005334</td>\n","      <td>-0.005020</td>\n","      <td>-0.001255</td>\n","      <td>-0.630127</td>\n","      <td>0.301270</td>\n","      <td>-1.026611</td>\n","      <td>0.944243</td>\n","      <td>...</td>\n","      <td>0.822474</td>\n","      <td>0.552660</td>\n","      <td>0.005962</td>\n","      <td>0.001255</td>\n","      <td>0.011610</td>\n","      <td>-0.350708</td>\n","      <td>-0.963013</td>\n","      <td>-0.650269</td>\n","      <td>unknown</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>1900-01-01 16:31:02.417621</th>\n","      <td>0.243751</td>\n","      <td>-0.407819</td>\n","      <td>0.843410</td>\n","      <td>0.013492</td>\n","      <td>-0.003138</td>\n","      <td>-0.003765</td>\n","      <td>-0.630371</td>\n","      <td>0.301392</td>\n","      <td>-1.026367</td>\n","      <td>0.945097</td>\n","      <td>...</td>\n","      <td>0.822474</td>\n","      <td>0.552660</td>\n","      <td>0.011610</td>\n","      <td>0.002510</td>\n","      <td>0.000941</td>\n","      <td>-0.350952</td>\n","      <td>-0.963013</td>\n","      <td>-0.650146</td>\n","      <td>unknown</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>1900-01-01 16:31:02.450953</th>\n","      <td>0.243965</td>\n","      <td>-0.407178</td>\n","      <td>0.843623</td>\n","      <td>0.001883</td>\n","      <td>-0.011923</td>\n","      <td>-0.008158</td>\n","      <td>-0.630615</td>\n","      <td>0.300537</td>\n","      <td>-1.026489</td>\n","      <td>0.945311</td>\n","      <td>...</td>\n","      <td>0.822687</td>\n","      <td>0.552446</td>\n","      <td>-0.002824</td>\n","      <td>-0.001883</td>\n","      <td>0.010041</td>\n","      <td>-0.351074</td>\n","      <td>-0.963013</td>\n","      <td>-0.650024</td>\n","      <td>unknown</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 47 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83ab4a3e-540a-4ee8-927e-9aa02ed36be6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-83ab4a3e-540a-4ee8-927e-9aa02ed36be6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-83ab4a3e-540a-4ee8-927e-9aa02ed36be6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]}]}