{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Bv9_aEQ4kCEgzPZ-9zjnYUZvbgO_OtA4","timestamp":1677010515769},{"file_id":"1WbviRoNfMEZwPiA0Jm0FruV9l8tODu_e","timestamp":1656703965031},{"file_id":"1RkiXI3GhB-rNtyUp_VYw05xiiuD_oDFA","timestamp":1612028534003}],"authorship_tag":"ABX9TyPgpVzSDeKhe3uQtE1Js7dW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Khc4g511HMYk"},"source":["#Gesture-Phase-Segmentation_load_dataset.ipynb\n","Loads the dataset from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/gesture+phase+segmentation) and returns train and test X/y numpy arrays.  This loader derived from TWRistAR version Feb'22.   Please follow the original dataset owners citation requests if you use this data in your work.\n","\n","The basic flow is:\n","* Download and unzip the dataset if not already present\n","* Convert each recording *session* into Intermediate Representation 1 (IR1) format - a datetime indexed pandas dataframe with columns for each channel plus the label and subject number.\n","* Transform the IR1 into IR2 - a set of three numpy arrays containing sliding window samples\n","   * X = (samples, time steps per sample, channels)  \n","   * y =  (samples, label) # activity classification  \n","   * s =  (samples, subject) # subject number\n","* Clean and further transforms the IR2 arrays as needed - note the transforms that can be applied here are train vs test dependent.   For example, the IR2 arrays in the training set may be rebalanced, but those in the test set should not.\n","* Concatenate the processed IR2 arrays into the final returned train/validate/test arrays.\n","\n","Set interactive to true to run the Jupyter Notebook version.  Note most of the calls are setup to test the functions, not process the entire dataset, to do that set interactive to false and run all so that main executes.   This notebook can be saved and run as a python file as well.\n","\n","\n","<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n","\n","[Lee B. Hinkle](https://userweb.cs.txstate.edu/~lbh31/), Texas State University, [IMICS Lab](https://imics.wp.txstate.edu/)  \n","TODO:\n","* Some files (a1_raw) have time discontinuity.  Need to address when forming sliding windows.\n","* The one-hot encoding should be moved to a common function.\n"]},{"cell_type":"markdown","source":["# Import Libraries and Common Load Dataset Code (from IMICS public repo)"],"metadata":{"id":"ghyvAqipvbvs"}},{"cell_type":"code","metadata":{"id":"q6H67o-YARCx","executionInfo":{"status":"ok","timestamp":1677450296925,"user_tz":360,"elapsed":4646,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["import os\n","import shutil #https://docs.python.org/3/library/shutil.html\n","from shutil import unpack_archive # to unzip\n","import time\n","import pandas as pd\n","import numpy as np\n","from numpy import savetxt\n","from tabulate import tabulate # for verbose tables, showing data\n","from tensorflow.keras.utils import to_categorical # for one-hot encoding\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from time import gmtime, strftime, localtime #for displaying Linux UTC timestamps in hh:mm:ss\n","from datetime import datetime, date\n","import urllib.request # to get files from web w/o !wget\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1677450296927,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"},"user_tz":360},"outputId":"4c81207a-e68c-4835-e0f1-cdf39f03dc83","id":"gajdw42Dt_yO"},"outputs":[{"output_type":"stream","name":"stdout","text":["Local load_data_utils.py found, skipping download\n","Local load_data_transforms.py found, skipping download\n"]}],"source":["def get_py_file(fname, url):\n","    \"\"\"checks for local file, if none downloads from URL.    \n","    :return: nothing\"\"\"\n","    #fname = 'load_data_utils.py'\n","    #ffname = os.path.join(my_dir,fname)\n","    if (os.path.exists(fname)):\n","        print (\"Local\",fname, \"found, skipping download\")\n","    else:\n","        print(\"Downloading\",fname, \"from IMICS git repo\")\n","        urllib.request.urlretrieve(url, filename=fname)\n","\n","get_py_file(fname = 'load_data_utils.py', url = 'https://raw.githubusercontent.com/imics-lab/load_data_time_series/main/load_data_utils.py')\n","get_py_file(fname = 'load_data_transforms.py', url = 'https://raw.githubusercontent.com/imics-lab/load_data_time_series/main/load_data_transforms.py')"]},{"cell_type":"code","source":["import load_data_transforms as xform\n","import load_data_utils as utils"],"metadata":{"id":"_Ny0oT3ecvZP","executionInfo":{"status":"ok","timestamp":1677450296929,"user_tz":360,"elapsed":21,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Global Parameters"],"metadata":{"id":"iDsgBVo_BFkc"}},{"cell_type":"code","metadata":{"id":"1LkvTO5hujPH","executionInfo":{"status":"ok","timestamp":1677450297056,"user_tz":360,"elapsed":148,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["# environment and execution parameters\n","my_dir = '.' # replace with absolute path if desired\n","dataset_dir = os.path.join(my_dir,'gesture_phase_dataset') # Where dataset will be unzipped\n","\n","interactive = True # for exploring data and functions interactively\n","verbose = True"],"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Gesture-Phase-Segmentation Dataset unique params\n","xform.time_steps = 30\n","xform.stride = 1\n","# the label map should contain all possible labels, it is used to convert from\n","# IR1 dataframe string labels of type categorical (saves a ton of memory) to \n","# integers for the IR2 and beyond numpy ndarrays.\n","label_map_gps = {\"label\":     {\"Rest\": 0, \"Preparation\": 1, \"Stroke\": 2,\n","                                \"Hold\": 3, \"Retraction\": 4}}"],"metadata":{"id":"ct3dGsecQOm8","executionInfo":{"status":"ok","timestamp":1677450297057,"user_tz":360,"elapsed":15,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"_arxQU-n6nKK","executionInfo":{"status":"ok","timestamp":1677450297058,"user_tz":360,"elapsed":15,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["interactive = False # don't run if interactive, automatically runs for .py version\n","verbose = False # to limit the called functions output"],"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_gesture_phase_dataset():\n","    \"\"\"checks for local zipfile, if none downloads from UCI repository\n","    after download will unzip the dataset into local directory.\n","    Assumes a global my_dir has been defined (default is my_dir = \".\")\n","    :return: nothing\"\"\"\n","    zip_fname = 'gesture_phase_dataset.zip'\n","    zip_ffname = os.path.join(my_dir,zip_fname)\n","    gps_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00302/gesture_phase_dataset.zip\"\n","    if (os.path.exists(zip_ffname)):\n","        if verbose:\n","            print (\"Local\",zip_ffname, \"found, skipping download\")\n","    else:\n","        print(\"Downloading Gesture-Phase-Segmentation dataset from UCI ML Repository\")\n","        urllib.request.urlretrieve(gps_url, zip_fname)\n","    if (os.path.isdir(dataset_dir)):\n","        if verbose:\n","            print(\"Found existing directory:\", dataset_dir, \"skipping unzip\")\n","    else:\n","        os.makedirs(dataset_dir)\n","        print(\"Unzipping Gesture Phase Segmentation file in\", dataset_dir, \"directory\")\n","        if (os.path.exists(zip_ffname)):\n","            shutil.unpack_archive(zip_ffname,dataset_dir,'zip')\n","        else:\n","            print(\"Error: \", zip_ffname, \" not found, exiting\")\n","    return\n","if interactive:\n","    get_gesture_phase_dataset()"],"metadata":{"id":"tlKEXl-BSrLO","executionInfo":{"status":"ok","timestamp":1677450297059,"user_tz":360,"elapsed":16,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def get_gps_ir1_dict():\n","    \"\"\"reads the Gesture-Phase-Segmentation raw .csv files in the global\n","    'dataset_dir'. This version uses dict to preserve original filenames.\n","    Returns: a dict containing IR1 dataframes.\"\"\"\n","    fn_list = ['a1_raw.csv', 'a2_raw.csv', 'a3_raw.csv',\n","           'b1_raw.csv', 'b3_raw.csv', 'c1_raw.csv','c3_raw.csv']\n","    ir1_df_dict = dict() # an empty dictionary\n","    for item in fn_list:\n","        subject = item[0] # the first letter of the filename a,b,c\n","        story = item[1] # the number after subject letter, 1,2,3\n","        ffname = os.path.join(dataset_dir,item)\n","        # print(subject, story, ffname)\n","        df = pd.read_csv(ffname)\n","        # change to 32-bit, credit/ref https://stackoverflow.com/questions/69188132/how-to-convert-all-float64-columns-to-float32-in-pandas\n","        # Select columns with 'float64' dtype  \n","        float64_cols = list(df.select_dtypes(include='float64'))\n","        # The same code again calling the columns\n","        df[float64_cols] = df[float64_cols].astype('float32')\n","        # b1_raw has an instance of alternate spelling.  Change to match others.\n","        df['phase'] = df['phase'].replace({'Preparação':'Preparation'})\n","        # Seems better to explicitly type the other columns vs object.\n","        df['phase']=df['phase'].astype('category')\n","\n","        df['sub'] = subject\n","        df['sub'] = [ ord(x) - 96 for x in df['sub']] # ord is unicode char\n","        df['sub']=df['sub'].astype('int8')\n","        df['story'] = story\n","        df['story']=df['story'].astype('int8')\n","        df.rename(columns={\"phase\": \"label\"}, inplace = True, errors=\"raise\") # phase was GPS dataset specific\n","\n","        # kinect sample rate is 15 or 30 fps, timestamp appears to\n","        # be a running counter not an actual UTC time.\n","        df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms') \n","        df.set_index('datetime',inplace=True)\n","        df = df.drop('timestamp', axis=1)\n","        ir1_df_dict[item.split('.')[0]]=df # key is root name of csv\n","    return ir1_df_dict\n","if interactive:\n","    df_dict = get_gps_ir1_dict()\n","    print(df_dict.keys())"],"metadata":{"executionInfo":{"status":"ok","timestamp":1677450297060,"user_tz":360,"elapsed":17,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"id":"p_EmZhbavtzi"},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Option to save/pickle the IR1 dataframes."],"metadata":{"id":"b75gKthUPKQD"}},{"cell_type":"code","source":["if interactive: \n","    save_dir = 'gesture_phase_raw_ir1'\n","    if (not os.path.isdir(save_dir)):\n","        os.mkdir(save_dir)\n","\n","    for df_name, ir1_df in df_dict.items() :\n","        ffname = os.path.join(save_dir,df_name) + '.pkl'\n","        ir1_df.to_pickle(ffname)"],"metadata":{"id":"0BkD0_Q0yYCR","executionInfo":{"status":"ok","timestamp":1677450297212,"user_tz":360,"elapsed":168,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["if interactive: \n","    my_df = df_dict['a1_raw']\n","    print(type(my_df))\n","    print(my_df.dtypes)\n","    display(my_df.head())\n","    my_df['lhx'].plot(figsize=(20, 10))"],"metadata":{"id":"7ClPrgS3wlBR","executionInfo":{"status":"ok","timestamp":1677450297213,"user_tz":360,"elapsed":13,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["if interactive:\n","    # labels will plot if they have been converted to ints \n","    my_df = xform.assign_ints_ir1_labels(df_dict['a1_raw'], label_mapping_dict = label_map_gps)\n","    my_df.plot(subplots=True, figsize=(20, 10)) # yay Pandas"],"metadata":{"id":"BMtfutS3yPFP","executionInfo":{"status":"ok","timestamp":1677450297214,"user_tz":360,"elapsed":13,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# find timegaps and split so that the resulting IR1 dataframes\n","# represent a continuous recording session\n","# use resampe/mean/interpolate to fill small gaps and make\n","# larger ones NaN.   Then get a dataframe of just the NaN\n","# rows and use that index to split the dataframe\n","# NOTE:  This is dataset specific in that it only handles one big gap\n","# Interesting that the plots merge and don't show separately\n","if interactive:\n","    my_df = df_dict['a1_raw']\n","    max_gaps_to_fill = 30\n","    # good resample explanation https://datastud.dev/posts/time-series-resample\n","    rs_df = my_df.resample('33ms').mean().interpolate(limit = max_gaps_to_fill)\n","    display(rs_df['lhx'].plot(figsize=(20, 10))) # NaN will not be plotted by default\n","    nan_rows = rs_df[rs_df['lhx'].isnull()] # notnull also available\n","    if (len(nan_rows.index)==0):\n","        print(\"No gaps exceeding\",max_gaps_to_fill,\"found\")\n","    else:\n","        print(len(nan_rows.index), \"rows with gaps large than\",max_gaps_to_fill,\"found\")\n","        gap_start, gap_end = nan_rows.index[0], nan_rows.index[-1]\n","        print(\"Start of gap\", gap_start)\n","        print(\" End of gap \", gap_end)\n","        df1 = rs_df.loc[rs_df.index[0]:gap_start]\n","        df1 = df1.iloc[:-max_gaps_to_fill] # drop the filled gap\n","        df2 = rs_df.loc[gap_end:rs_df.index[-1]]\n","        df2 = df2.iloc[1:] # drop the one NaN row due to slice\n","        display(df1['lhx'].plot(figsize=(20, 10)))\n","        display(df2['lhx'].plot(figsize=(20, 10)))\n","\n"],"metadata":{"id":"-aqI88B5Md0X","executionInfo":{"status":"ok","timestamp":1677450297215,"user_tz":360,"elapsed":14,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Use Common Transforms to generate IR3 and final arrays"],"metadata":{"id":"svbf8hj0JQ9z"}},{"cell_type":"code","metadata":{"id":"rJp5v319Ybxa","executionInfo":{"status":"ok","timestamp":1677450297216,"user_tz":360,"elapsed":15,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["def get_ir3_from_dict(ir1_dict):\n","    \"\"\"Processes a dictionary with key = IR1 source filename, item = IR1 df\n","    NOTE:  This version currently specific to Gesture dataset\n","    \"\"\"\n","    ir3_X = np.zeros(shape=(1,xform.time_steps,19), dtype = 'float32')\n","    ir3_y = np.zeros(shape=(1,1),dtype='int8') # newer int method\n","    #ir3_y = np.full(shape=(1,1), fill_value='n/a',dtype='<U10') # unicode 10 char\n","    ir3_sub = np.zeros(shape=(1,1),dtype='int16') # one subject number per entry\n","    ir3_ss_times = np.zeros(shape=(1,2),dtype='datetime64') # start/stop times of sliding window\n","    for ir1_fname, ir1_df in ir1_dict.items():\n","        if verbose:\n","            print('Processing ', ir1_fname)\n","        ir1_df = xform.assign_ints_ir1_labels(ir1_df, label_mapping_dict = label_map_gps)\n","        ir2_X, ir2_y, ir2_sub, ir2_ss_time, channel_list = xform.get_ir2_from_ir1(ir1_df)\n","        ir2_X, ir2_y, ir2_sub, ir2_ss_time = xform.clean_ir2(ir2_X, ir2_y, ir2_sub, ir2_ss_time)\n","        ir2_X, ir2_y, ir2_sub, ir2_ss_time = xform.drop_label_ir2_ir3(ir2_X, ir2_y, ir2_sub, ir2_ss_time, 99)\n","        ir3_X = np.vstack([ir3_X, ir2_X])\n","        ir3_y = np.vstack([ir3_y, ir2_y])\n","        ir3_sub = np.vstack([ir3_sub, ir2_sub])\n","        ir3_ss_times = np.vstack([ir3_ss_times, ir2_ss_time])\n","    #delete first row placeholders\n","    X = np.delete(ir3_X, (0), axis=0) \n","    y = np.delete(ir3_y, (0), axis=0) \n","    sub = np.delete(ir3_sub, (0), axis=0)\n","    sub = np.delete(ir3_sub, (0), axis=0)\n","    ss_times = np.delete(ir3_ss_times, (0), axis=0)\n","\n","    xys_info = 'Needs work!\\n'\n","    # xys_info += '\\n'.join([str(elem) for elem in zip_flist]) # conv list to string\n","    # xys_info += '\\nTime steps =' + str(time_steps) + ', Step =' + str(stride) + ', no resample\\n'\n","    # xys_info += 'Final Shapes\\n'\n","    # xys_info += \"X shape \" + str(X.shape) + \" dtype = \" + str(X.dtype) + \"\\n\"\n","    # xys_info += \"y shape \" + str(y.shape) + \" dtype = \" + str(y.dtype) + \"\\n\"\n","    # xys_info += \"sub shape \" + str(sub.shape) + \" dtype = \" + str(sub.dtype) + \"\\n\"\n","    xys_info += \"IR1 Channel names:\" + str(channel_list) + \"\\n\"\n","    # # Get final counts for label ndarray - not quite as easy as pandas df\n","    # xys_info += \"Final Label Counts\\n\"\n","    # unique, counts = np.unique(y, return_counts=True)\n","    # xys_info += str(np.asarray((unique, counts)).T)\n","    # xys_info += \"\\nSamples per Subject\\n\"\n","    # unique, counts = np.unique(sub, return_counts=True)\n","    # xys_info += str(np.asarray((unique, counts)).T)\n","    return X, y, sub, ss_times, xys_info\n","if interactive:\n","    X, y, sub, ss_times, xys_info = get_ir3_from_dict(df_dict)\n","    headers = (\"array\",\"shape\", \"object type\", \"data type\")\n","    mydata = [(\"X:\", X.shape, type(X), X.dtype),\n","            (\"y:\", y.shape ,type(y), y.dtype),\n","            (\"sub:\", sub.shape, type(sub), sub.dtype),\n","            (\"ss_time:\", ss_times.shape, type(ss_times), ss_times.dtype)]\n","    print(tabulate(mydata, headers=headers))\n","    unique, counts = np.unique(y, return_counts=True)\n","    print('Label Counts:\\n',str(np.asarray((unique, counts)).T))\n","    print(label_map_gps)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"trfLorthy59i","executionInfo":{"status":"ok","timestamp":1677450297352,"user_tz":360,"elapsed":10,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["def gesture_phase_segmentation_load_dataset(\n","    #verbose = False,\n","    #use_saved_xysub = False, # get X,y,sub from zip, True = faster to used saved ones\n","    incl_val_group = False, # split train into train and validate\n","    split_subj = dict\n","                (train_subj = [1,2,3],\n","                validation_subj = [],\n","                test_subj = []),\n","    #keep_channel_list = ['accel_ttl'],\n","    one_hot_encode = True, # make y into multi-column one-hot, one for each activity\n","    return_info_dict = False, # return dict of meta info along with ndarrays\n","    suppress_warn = False # special case for stratified warning\n","    ):\n","    \"\"\"Downloads the Phase-Gesture-Segmentation dataset from UCI repository.\n","    Each csv file is converted into an IR1 dataframe and placed into a dictionary.\n","    Since this dataset is so small all subjects are placed into the train set\n","    and the validation set is a stratification of the train set.   The test set\n","    is empty by default (usually the test set is pulled out before model tuning)\n","    \"\"\"\n","    log_info = \"Generated by Gesture-Phase-Segmentation_load_dataset.ipynb\\n\"\n","    today = date.today()\n","    log_info += today.strftime(\"%B %d, %Y\") + \"\\n\"\n","    log_info += \"sub dict = \" + str(split_subj) + \"\\n\"\n","    get_gesture_phase_dataset()\n","    df_dict = get_gps_ir1_dict()\n","    X, y, sub, ss_times, xys_info = get_ir3_from_dict(df_dict)\n","    #if (not use_saved_xysub):\n","    #   X, y, sub, xys_info = get_ir3()\n","    # Drop unwanted channels from X\n","    #log_info += \"Keeping channels\" + str(keep_channel_list) + \"\\n\"\n","    #X = limit_channel_ir3(X, keep_channel_list = keep_channel_list)\n","    # write initial array info to log_info\n","    headers = (\"Initial Array\",\"shape\", \"object type\", \"data type\")\n","    mydata = [(\"X\", X.shape, type(X), X.dtype),\n","              (\"y\", y.shape, type(y), y.dtype),\n","              (\"sub\", sub.shape, type(sub), sub.dtype)]\n","    if (verbose):\n","        print(tabulate(mydata, headers=headers))\n","    log_info += tabulate(mydata, headers=headers) + \"\\n\"\n","\n","    if (one_hot_encode):\n","        # integer encode\n","        y_vector = np.ravel(y) #encoder won't take column vector\n","        le = LabelEncoder()\n","        integer_encoded = le.fit_transform(y_vector) #convert from string to int\n","        name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n","        if (verbose):\n","            print(\"One-hot-encoding: category names -> int -> one-hot \\n\")\n","            print(name_mapping) # seems risky as interim step before one-hot\n","        log_info += \"One Hot:\" + str(name_mapping) +\"\\n\\n\"\n","        onehot_encoder = OneHotEncoder(sparse=False)\n","        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","        onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","        y=onehot_encoded.astype('uint8')\n","        #return X,y\n","    # split by subject number pass in dictionary\n","    sub_num = np.ravel(sub[ : , 0] ) # convert shape to (1047,)\n","    # this code is different from typical due to limited subjects,\n","    # all not test subjects data is placed into train which is then \n","    # split using stratification - validation group is not sub independent\n","    train_index = np.nonzero(np.isin(sub_num, split_subj['train_subj'] + \n","                                        split_subj['validation_subj']))\n","    x_train = X[train_index]\n","    y_train = y[train_index]\n","    if (incl_val_group):\n","        if not suppress_warn:\n","            print(\"Warning: Due to limited subjects the validation group is a stratified\")\n","            print(\"90/10 split of the training group.  It is not subject independent.\")\n","        # split training into training + validate using stratify - note that the\n","        # validation set is not subject independent (hard to achieve with limited\n","        # subjects).   The test set however is subject independent and as a result\n","        # will have much lower accuracy.  Another option is to tag a few of the\n","        # activities for inclusion in validation.  See\n","        # https://github.com/imics-lab/Semi-Supervised-HAR-e4-Wristband\n","        # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","        x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.10, random_state=42, stratify=y_train)\n","\n","    test_index = np.nonzero(np.isin(sub_num, split_subj['test_subj']))\n","    x_test = X[test_index]\n","    y_test = y[test_index]\n","\n","    headers = (\"Returned Array\",\"shape\", \"object type\", \"data type\")\n","    mydata = [(\"x_train:\", x_train.shape, type(x_train), x_train.dtype),\n","                    (\"y_train:\", y_train.shape ,type(y_train), y_train.dtype)]\n","    if (incl_val_group):\n","        mydata += [(\"x_validation:\", x_validation.shape, type(x_validation), x_validation.dtype),\n","                        (\"y_validation:\", y_validation.shape ,type(y_validation), y_validation.dtype)]\n","    mydata += [(\"x_test:\", x_test.shape, type(x_test), x_test.dtype),\n","                    (\"y_test:\", y_test.shape ,type(y_test), y_test.dtype)]\n","    if (verbose):\n","        print(tabulate(mydata, headers=headers))\n","    log_info += tabulate(mydata, headers=headers)\n","    if (incl_val_group):\n","        if (return_info_dict):\n","            return x_train, y_train, x_validation, y_validation, x_test, y_test, log_info\n","        else:\n","            return x_train, y_train, x_validation, y_validation, x_test, y_test\n","    else:\n","        if (return_info_dict):\n","            return x_train, y_train, x_test, y_test, log_info\n","        else:\n","            return x_train, y_train, x_test, y_test\n"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Main is setup to be a demo and bit of unit test."],"metadata":{"id":"tncwIiZaB3j3"}},{"cell_type":"code","metadata":{"id":"MaT1dfqavvtk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677450298723,"user_tz":360,"elapsed":1380,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"outputId":"efa8c30e-821c-46b7-e1d3-f5a9d70c2a33"},"source":["if __name__ == \"__main__\":\n","    verbose = False\n","    print(\"Get Gesture Phase Segmentation using defaults - simple and easy!\")\n","    x_train, y_train, x_test, y_test \\\n","                             = gesture_phase_segmentation_load_dataset()\n","    headers = (\"Array\",\"shape\", \"data type\")\n","    mydata = [(\"x_train:\", x_train.shape, x_train.dtype),\n","            (\"y_train:\", y_train.shape, y_train.dtype),\n","            (\"x_test:\", x_test.shape, x_test.dtype),\n","            (\"y_test:\", y_test.shape, y_test.dtype)]\n","    print(\"\\n\",tabulate(mydata, headers=headers))\n","    print ('\\n','-'*72)\n","\n","    print(\"Get Gesture Phase Segmentation with validation and info file\\n\")\n","    x_train, y_train, x_valid, y_valid, x_test, y_test, log_info \\\n","                             = gesture_phase_segmentation_load_dataset(\n","                                 incl_val_group = True,\n","                                 return_info_dict = True)\n","\n","    headers = (\"Array\",\"shape\", \"data type\")\n","    mydata = [(\"x_train:\", x_train.shape, x_train.dtype),\n","            (\"y_train:\", y_train.shape, y_train.dtype),\n","            (\"x_valid:\", x_valid.shape, x_valid.dtype),\n","            (\"y_valid:\", y_valid.shape, y_valid.dtype),\n","            (\"x_test:\", x_test.shape, x_test.dtype),\n","            (\"y_test:\", y_test.shape, y_test.dtype)]\n","    print(\"\\n\",tabulate(mydata, headers=headers))\n","    print(\"\\n----------- Contents of returned log_info ---------------\")\n","    print(log_info)\n","    print(\"\\n------------- End of returned log_info -----------------\")"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Get Gesture Phase Segmentation using defaults - simple and easy!\n","\n"," Array     shape           data type\n","--------  --------------  -----------\n","x_train:  (2815, 30, 19)  float32\n","y_train:  (2815, 5)       uint8\n","x_test:   (0, 30, 19)     float32\n","y_test:   (0, 5)          uint8\n","\n"," ------------------------------------------------------------------------\n","Get Gesture Phase Segmentation with validation and info file\n","\n","Warning: Due to limited subjects the validation group is a stratified\n","90/10 split of the training group.  It is not subject independent.\n","\n"," Array     shape           data type\n","--------  --------------  -----------\n","x_train:  (2533, 30, 19)  float32\n","y_train:  (2533, 5)       uint8\n","x_valid:  (282, 30, 19)   float32\n","y_valid:  (282, 5)        uint8\n","x_test:   (0, 30, 19)     float32\n","y_test:   (0, 5)          uint8\n","\n","----------- Contents of returned log_info ---------------\n","Generated by Gesture-Phase-Segmentation_load_dataset.ipynb\n","February 26, 2023\n","sub dict = {'train_subj': [1, 2, 3], 'validation_subj': [], 'test_subj': []}\n","Initial Array    shape           object type              data type\n","---------------  --------------  -----------------------  -----------\n","X                (2815, 30, 19)  <class 'numpy.ndarray'>  float32\n","y                (2815, 1)       <class 'numpy.ndarray'>  int8\n","sub              (2815, 1)       <class 'numpy.ndarray'>  int16\n","One Hot:{0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n","\n","Returned Array    shape           object type              data type\n","----------------  --------------  -----------------------  -----------\n","x_train:          (2533, 30, 19)  <class 'numpy.ndarray'>  float32\n","y_train:          (2533, 5)       <class 'numpy.ndarray'>  uint8\n","x_validation:     (282, 30, 19)   <class 'numpy.ndarray'>  float32\n","y_validation:     (282, 5)        <class 'numpy.ndarray'>  uint8\n","x_test:           (0, 30, 19)     <class 'numpy.ndarray'>  float32\n","y_test:           (0, 5)          <class 'numpy.ndarray'>  uint8\n","\n","------------- End of returned log_info -----------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"XXDA5C2pbVsx"},"source":["#Save arrays to drive\n","This is common code and untested - TWristAR is small so download and processing is fast.\n","\n","For some of the larger datsets it is a big time benefit to store the arrays either before or after train/test split.  "]},{"cell_type":"code","metadata":{"id":"b2S4BThhXuqw","executionInfo":{"status":"ok","timestamp":1677450298726,"user_tz":360,"elapsed":12,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["if False: #change to true to save files interactively\n","    output_dir = '/content/drive/MyDrive/Processed_Datasets/TWristAR/all-sensors'\n","    if (os.path.isdir(output_dir)):\n","        #quick check for existing files, '.ipynb_checkpoints' file \n","        #makes it more complicated to see if directory is empty\n","        if (not os.path.isfile(output_dir + '/X.npy')):\n","            summary = \"TWristAR data\\n\"\n","            summary += \"Saved to \" + output_dir + \"\\n\"\n","            summary += \"Generated by TWristAR_load_data.ipynb\"\n","            summary += \" on \" + time.strftime('%b-%d-%Y_%H%M', time.localtime())\n","            summary += \"this version for fusion of learned representation work\\n\"\n","            summary += \"contains data from all 4 e4 sensors\"\n","            info_fname = output_dir +'/'+'README.txt'\n","            full_info = summary + \"\\n\" + xys_info + \"\\n\"\n","            print(full_info)\n","\n","            with open(info_fname, \"w\") as file_object:\n","                file_object.write(full_info)\n","\n","            if True:\n","                np.save(output_dir + '/'+'X.npy',X)\n","                np.save(output_dir + '/'+'y.npy',y)\n","                np.save(output_dir + '/'+'sub.npy',sub)\n","        else:\n","            print(\"Error \"+output_dir+\" contains X.npy, please delete files\")\n","    else:\n","        print(output_dir + \" not found, please create directory\") "],"execution_count":16,"outputs":[]},{"cell_type":"code","source":["if interactive:\n","    import matplotlib.pyplot as plt # for plotting"],"metadata":{"id":"C3TWmOxOQhRG","executionInfo":{"status":"ok","timestamp":1677450298727,"user_tz":360,"elapsed":12,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"6L_iQarrVS-2","executionInfo":{"status":"ok","timestamp":1677450298728,"user_tz":360,"elapsed":13,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["# Plot y - must convert to numeric first\n","def plot_activities():\n","    uniques, y_num = np.unique(y, return_inverse=True)\n","    print (uniques)\n","    plt.plot(y_num) \n","    plt.show()\n","if (interactive):\n","    plot_activities()"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"6zSP9lPX_esj","executionInfo":{"status":"ok","timestamp":1677450298874,"user_tz":360,"elapsed":159,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["def plot_subjects():\n","    uniques, s_num = np.unique(sub, return_inverse=True)\n","    print (uniques)\n","    plt.plot(s_num) \n","    plt.show()\n","if (interactive):\n","    plot_subjects()"],"execution_count":19,"outputs":[]}]}