{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Bv9_aEQ4kCEgzPZ-9zjnYUZvbgO_OtA4","timestamp":1677010515769},{"file_id":"1WbviRoNfMEZwPiA0Jm0FruV9l8tODu_e","timestamp":1656703965031},{"file_id":"1RkiXI3GhB-rNtyUp_VYw05xiiuD_oDFA","timestamp":1612028534003}],"authorship_tag":"ABX9TyPeoZewgQ2ge81wjYKFvtco"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Khc4g511HMYk"},"source":["#Gesture-Phase-Segmentation_load_dataset.ipynb\n","Loads the dataset from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/gesture+phase+segmentation) and returns train and test X/y numpy arrays.  This loader derived from TWRistAR version Feb'22.   Please follow the original dataset owners citation requests if you use this data in your work.\n","\n","The basic flow is:\n","* Download and unzip the dataset if not already present\n","* Convert each recording *session* into Intermediate Representation 1 (IR1) format - a datetime indexed pandas dataframe with columns for each channel plus the label and subject number.\n","* Transform the IR1 into IR2 - a set of three numpy arrays containing sliding window samples\n","   * X = (samples, time steps per sample, channels)  \n","   * y =  (samples, label) # activity classification  \n","   * s =  (samples, subject) # subject number\n","* Clean and further transforms the IR2 arrays as needed - note the transforms that can be applied here are train vs test dependent.   For example, the IR2 arrays in the training set may be rebalanced, but those in the test set should not.\n","* Concatenate the processed IR2 arrays into the final returned train/validate/test arrays.\n","\n","Set interactive to true to run the Jupyter Notebook version.  Note most of the calls are setup to test the functions, not process the entire dataset, to do that set interactive to false and run all so that main executes.   This notebook can be saved and run as a python file as well.\n","\n","\n","<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n","\n","[Lee B. Hinkle](https://userweb.cs.txstate.edu/~lbh31/), Texas State University, [IMICS Lab](https://imics.wp.txstate.edu/)  \n","TODO:\n","* Some files (a1_raw) have time discontinuity.  Need to address when forming sliding windows.\n","* The one-hot encoding should be moved to a common function.\n"]},{"cell_type":"markdown","source":["# Import Libraries and Common Load Dataset Code (from IMICS public repo)"],"metadata":{"id":"ghyvAqipvbvs"}},{"cell_type":"code","metadata":{"id":"q6H67o-YARCx","executionInfo":{"status":"ok","timestamp":1678420069260,"user_tz":360,"elapsed":7048,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["import os\n","import shutil #https://docs.python.org/3/library/shutil.html\n","from shutil import unpack_archive # to unzip\n","import time\n","import pandas as pd\n","import numpy as np\n","from numpy import savetxt\n","from tabulate import tabulate # for verbose tables, showing data\n","from tensorflow.keras.utils import to_categorical # for one-hot encoding\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from time import gmtime, strftime, localtime #for displaying Linux UTC timestamps in hh:mm:ss\n","from datetime import datetime, date\n","import urllib.request # to get files from web w/o !wget\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":361,"status":"ok","timestamp":1678420069602,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"},"user_tz":360},"outputId":"5ad9ecc6-b0f6-4d00-fd29-753845b334b2","id":"gajdw42Dt_yO"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading load_data_utils.py from IMICS git repo\n","Downloading load_data_transforms.py from IMICS git repo\n"]}],"source":["def get_py_file(fname, url):\n","    \"\"\"checks for local file, if none downloads from URL.    \n","    :return: nothing\"\"\"\n","    #fname = 'load_data_utils.py'\n","    #ffname = os.path.join(my_dir,fname)\n","    if (os.path.exists(fname)):\n","        print (\"Local\",fname, \"found, skipping download\")\n","    else:\n","        print(\"Downloading\",fname, \"from IMICS git repo\")\n","        urllib.request.urlretrieve(url, filename=fname)\n","\n","get_py_file(fname = 'load_data_utils.py', url = 'https://raw.githubusercontent.com/imics-lab/load_data_time_series/main/load_data_utils.py')\n","get_py_file(fname = 'load_data_transforms.py', url = 'https://raw.githubusercontent.com/imics-lab/load_data_time_series/main/load_data_transforms.py')"]},{"cell_type":"code","source":["import load_data_transforms as xform\n","import load_data_utils as utils"],"metadata":{"id":"_Ny0oT3ecvZP","executionInfo":{"status":"ok","timestamp":1678420069776,"user_tz":360,"elapsed":176,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Global Parameters"],"metadata":{"id":"iDsgBVo_BFkc"}},{"cell_type":"code","metadata":{"id":"1LkvTO5hujPH","executionInfo":{"status":"ok","timestamp":1678420069777,"user_tz":360,"elapsed":4,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["# environment and execution parameters\n","my_dir = '.' # replace with absolute path if desired\n","dataset_dir = os.path.join(my_dir,'gesture_phase_dataset') # Where dataset will be unzipped\n","\n","interactive = True # for exploring data and functions interactively\n","verbose = True"],"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Gesture-Phase-Segmentation Dataset unique params\n","xform.time_steps = 30\n","xform.stride = 5\n","# the label map should contain all possible labels, it is used to convert from\n","# IR1 dataframe string labels of type categorical (saves a ton of memory) to \n","# integers for the IR2 and beyond numpy ndarrays.\n","label_map_gps = {\"label\":     {\"Rest\": 0, \"Preparation\": 1, \"Stroke\": 2,\n","                                \"Hold\": 3, \"Retraction\": 4}}"],"metadata":{"id":"ct3dGsecQOm8","executionInfo":{"status":"ok","timestamp":1678420069778,"user_tz":360,"elapsed":4,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"_arxQU-n6nKK","executionInfo":{"status":"ok","timestamp":1678420070338,"user_tz":360,"elapsed":564,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["interactive = False # don't run if interactive, automatically runs for .py version\n","verbose = False # to limit the called functions output"],"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_gesture_phase_dataset():\n","    \"\"\"checks for local zipfile, if none downloads from UCI repository\n","    after download will unzip the dataset into local directory.\n","    Assumes a global my_dir has been defined (default is my_dir = \".\")\n","    :return: nothing\"\"\"\n","    zip_fname = 'gesture_phase_dataset.zip'\n","    zip_ffname = os.path.join(my_dir,zip_fname)\n","    gps_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00302/gesture_phase_dataset.zip\"\n","    if (os.path.exists(zip_ffname)):\n","        if verbose:\n","            print (\"Local\",zip_ffname, \"found, skipping download\")\n","    else:\n","        print(\"Downloading Gesture-Phase-Segmentation dataset from UCI ML Repository\")\n","        urllib.request.urlretrieve(gps_url, zip_fname)\n","    if (os.path.isdir(dataset_dir)):\n","        if verbose:\n","            print(\"Found existing directory:\", dataset_dir, \"skipping unzip\")\n","    else:\n","        os.makedirs(dataset_dir)\n","        print(\"Unzipping Gesture Phase Segmentation file in\", dataset_dir, \"directory\")\n","        if (os.path.exists(zip_ffname)):\n","            shutil.unpack_archive(zip_ffname,dataset_dir,'zip')\n","        else:\n","            print(\"Error: \", zip_ffname, \" not found, exiting\")\n","    return\n","if interactive:\n","    get_gesture_phase_dataset()"],"metadata":{"id":"tlKEXl-BSrLO","executionInfo":{"status":"ok","timestamp":1678420071156,"user_tz":360,"elapsed":15,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def get_gps_ir1_dict(include_story = False):\n","    \"\"\"reads the Gesture-Phase-Segmentation raw .csv files in the global\n","    'dataset_dir'. This version uses dict to preserve original filenames.\n","    Returns: a dict containing IR1 dataframes.\"\"\"\n","    fn_list = ['a1_raw.csv', 'a2_raw.csv', 'a3_raw.csv',\n","           'b1_raw.csv', 'b3_raw.csv', 'c1_raw.csv','c3_raw.csv']\n","    get_gesture_phase_dataset()\n","    ir1_df_dict = dict() # an empty dictionary\n","    for item in fn_list:\n","        subject = item[0] # the first letter of the filename a,b,c\n","        story = item[1] # the number after subject letter, 1,2,3\n","        ffname = os.path.join(dataset_dir,item)\n","        # print(subject, story, ffname)\n","        df = pd.read_csv(ffname)\n","        # change to 32-bit, credit/ref https://stackoverflow.com/questions/69188132/how-to-convert-all-float64-columns-to-float32-in-pandas\n","        # Select columns with 'float64' dtype  \n","        float64_cols = list(df.select_dtypes(include='float64'))\n","        # The same code again calling the columns\n","        df[float64_cols] = df[float64_cols].astype('float32')\n","        # b1_raw has an instance of alternate spelling.  Change to match others.\n","        df['phase'] = df['phase'].replace({'Preparação':'Preparation'})\n","        # Seems better to explicitly type the other columns vs object.\n","        df['phase']=df['phase'].astype('category')\n","\n","        df['sub'] = subject\n","        df['sub'] = [ ord(x) - 96 for x in df['sub']] # ord is unicode char\n","        df['sub']=df['sub'].astype('int8')\n","        if include_story:\n","            df['story'] = story\n","            df['story']=df['story'].astype('int8')\n","        df.rename(columns={\"phase\": \"label\"}, inplace = True, errors=\"raise\") # phase was GPS dataset specific\n","\n","        # kinect sample rate is 15 or 30 fps, timestamp appears to\n","        # be a running counter not an actual UTC time.\n","        df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms') \n","        df.set_index('datetime',inplace=True)\n","        df = df.drop('timestamp', axis=1)\n","        ir1_df_dict[item.split('.')[0]]=df # key is root name of csv\n","    return ir1_df_dict\n","if interactive:\n","    ir1_dict = get_gps_ir1_dict()\n","    print(ir1_dict.keys())"],"metadata":{"executionInfo":{"status":"ok","timestamp":1678420071156,"user_tz":360,"elapsed":13,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"id":"p_EmZhbavtzi"},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def split_ir1_dict_by_sub(ir1_dict, split_subj_dict):\n","    \"\"\"This splits the ir1 dictionary of all files into three separate ones\n","    based on the subject and split_subj_dict.  Primarily used to change the\n","    processing between the train/valid sets (mixed windows discarded, classes\n","    balanced) and the test test (mode labeling, little other processing)\"\"\"\n","    # TODO: check for mixed subs and double allocations\n","    # empty dictionaries\n","    ir1_df_dict_train = dict() \n","    ir1_df_dict_valid = dict() \n","    ir1_df_dict_test = dict() \n","    for key, item in ir1_dict.items():\n","        extracted_sub = item['sub'].iloc[0] # first row sub number\n","        #print(key,item['sub'].iloc[0]) # first row sub number\n","        if extracted_sub in split_subj_dict['train_subj']:\n","            ir1_df_dict_train[key] = item\n","        if extracted_sub in split_subj_dict['valid_subj']:\n","            ir1_df_dict_valid[key] = item\n","        if extracted_sub in split_subj_dict['test_subj']:\n","            ir1_df_dict_test[key] = item\n","    return ir1_df_dict_train,ir1_df_dict_valid,ir1_df_dict_test\n","\n","if interactive:\n","    split_subj = dict(train_subj = [1], valid_subj = [2], test_subj = [3])\n","    ir1_df_dict_train,ir1_df_dict_valid,ir1_df_dict_test = split_ir1_dict_by_sub(ir1_dict, split_subj_dict = split_subj)\n","    print(\"Train:\", ir1_df_dict_train.keys())\n","    print(\"Valid:\",ir1_df_dict_valid.keys())\n","    print(\"Test :\",ir1_df_dict_test.keys())"],"metadata":{"id":"zQyiYh9oZJ7i","executionInfo":{"status":"ok","timestamp":1678420071157,"user_tz":360,"elapsed":13,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Exploratory code for dealing with the data gaps in the dataset"],"metadata":{"id":"b75gKthUPKQD"}},{"cell_type":"code","source":["if interactive: \n","    my_df = ir1_dict['a1_raw']\n","    print(type(my_df))\n","    print(my_df.dtypes)\n","    display(my_df.head())\n","    my_df['lhx'].plot(figsize=(20, 10))"],"metadata":{"id":"7ClPrgS3wlBR","executionInfo":{"status":"ok","timestamp":1678420071157,"user_tz":360,"elapsed":10,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["if interactive:\n","    # labels will plot if they have been converted to ints \n","    my_df = xform.assign_ints_ir1_labels(ir1_dict['a1_raw'], label_mapping_dict = label_map_gps)\n","    my_df.plot(subplots=True, figsize=(20, 10)) # yay Pandas"],"metadata":{"id":"BMtfutS3yPFP","executionInfo":{"status":"ok","timestamp":1678420071158,"user_tz":360,"elapsed":10,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# find timegaps and split so that the resulting IR1 dataframes\n","# represent a continuous recording session\n","# use resampe/mean/interpolate to fill small gaps and make\n","# larger ones NaN.   Then get a dataframe of just the NaN\n","# rows and use that index to split the dataframe\n","# NOTE:  This is dataset specific in that it only handles one big gap\n","# Interesting that the plots merge and don't show separately\n","if interactive:\n","    my_df = ir1_dict['a1_raw']\n","    max_gaps_to_fill = 30\n","    # good resample explanation https://datastud.dev/posts/time-series-resample\n","    rs_df = my_df.resample('33ms').mean().interpolate(limit = max_gaps_to_fill)\n","    display(rs_df['lhx'].plot(figsize=(20, 10))) # NaN will not be plotted by default\n","    nan_rows = rs_df[rs_df['lhx'].isnull()] # notnull also available\n","    if (len(nan_rows.index)==0):\n","        print(\"No gaps exceeding\",max_gaps_to_fill,\"found\")\n","    else:\n","        print(len(nan_rows.index), \"rows with gaps large than\",max_gaps_to_fill,\"found\")\n","        gap_start, gap_end = nan_rows.index[0], nan_rows.index[-1]\n","        print(\"Start of gap\", gap_start)\n","        print(\" End of gap \", gap_end)\n","        df1 = rs_df.loc[rs_df.index[0]:gap_start]\n","        df1 = df1.iloc[:-max_gaps_to_fill] # drop the filled gap\n","        df2 = rs_df.loc[gap_end:rs_df.index[-1]]\n","        df2 = df2.iloc[1:] # drop the one NaN row due to slice\n","        display(df1['lhx'].plot(figsize=(20, 10)))\n","        display(df2['lhx'].plot(figsize=(20, 10)))"],"metadata":{"id":"-aqI88B5Md0X","executionInfo":{"status":"ok","timestamp":1678420071158,"user_tz":360,"elapsed":10,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# The dataset specific code to generate the dictionary of IR1 dataframes is complete.  Now use Shared Transforms to generate the final output arrays."],"metadata":{"id":"k4RnDlHwnYzz"}},{"cell_type":"code","metadata":{"id":"trfLorthy59i","executionInfo":{"status":"ok","timestamp":1678420071159,"user_tz":360,"elapsed":10,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["def gesture_phase_segmentation_load_dataset(\n","    incl_val_group = False, # split train into train and validate\n","    split_subj = dict\n","                (train_subj = [1,2],\n","                valid_subj = [],\n","                test_subj = [3]),\n","    one_hot_encode = True, # make y into multi-column one-hot, one for each activity\n","    return_info_dict = False, # return dict of meta info along with ndarrays\n","    suppress_warn = False # special case for stratified warning\n","    ):\n","    \"\"\"Downloads the Phase-Gesture-Segmentation dataset from UCI repository.\n","    Each csv file is converted into an IR1 dataframe and placed into a dictionary.\n","    Since this dataset is so small all subjects are placed into the train set\n","    and the validation set is a stratification of the train set.   The test set\n","    is empty by default (usually the test set is pulled out before model tuning)\n","    \"\"\"\n","    log_info = \"Generated by Gesture-Phase-Segmentation_load_dataset.ipynb\\n\"\n","    today = date.today()\n","    log_info += today.strftime(\"%B %d, %Y\") + \"\\n\"\n","    log_info += \"sub dict = \" + str(split_subj) + \"\\n\"\n","\n","    ir1_dict = get_gps_ir1_dict()\n","\n","    # split the IR1 dict by subject so each can be processed separately.\n","    ir1_dict_train,ir1_dict_valid,ir1_dict_test = split_ir1_dict_by_sub(ir1_dict, split_subj_dict = split_subj)\n","    if True:  # change back to verbose when done debugging!\n","        print(\"Train:\", ir1_dict_train.keys())\n","        print(\"Valid:\",ir1_dict_valid.keys())\n","        print(\"Test :\",ir1_dict_test.keys())\n","    x_train, y_train, sub_train, ss_times_train, xys_info = xform.get_ir3_from_dict(ir1_dict_train, label_map = label_map_gps, label_method = 'drop')\n","    #x_valid, y_valid, sub_valid, ss_times_valid, xys_info = xform.get_ir3_from_dict(ir1_dict_valid, label_map = label_map_gps)\n","    x_test, y_test, sub_test, ss_times_test, xys_info = xform.get_ir3_from_dict(ir1_dict_test, label_map = label_map_gps, label_method = 'mode')\n","\n","    # headers = (\"Initial Array\",\"shape\", \"object type\", \"data type\")\n","    # mydata = [(\"X\", X.shape, type(X), X.dtype),\n","    #           (\"y\", y.shape, type(y), y.dtype),\n","    #           (\"sub\", sub.shape, type(sub), sub.dtype)]\n","    # if (verbose):\n","    #     print(tabulate(mydata, headers=headers))\n","    # log_info += tabulate(mydata, headers=headers) + \"\\n\"\n","\n","    if (one_hot_encode):\n","        # using newer code, ints only, from Fusion of Learned Reps work\n","        enc = OneHotEncoder(categories='auto', sparse_output=False)\n","        y_train = enc.fit_transform(y_train)\n","        #y_valid = enc.fit_transform(y_valid)\n","        y_test = enc.fit_transform(y_test)\n","        # integer encode\n","        # y_vector_train = np.ravel(y_train) #encoder won't take column vector\n","        # y_vector_valid = np.ravel(y_valid) #encoder won't take column vector\n","        # y_vector_test = np.ravel(y_test) #encoder won't take column vector\n","        # le = LabelEncoder()\n","        # integer_encoded = le.fit_transform(y_vector_train) #convert from string to int\n","        # name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n","        # if (verbose):\n","        #     print(\"One-hot-encoding: category names -> int -> one-hot \\n\")\n","        #     print(name_mapping) # seems risky as interim step before one-hot\n","        # log_info += \"One Hot:\" + str(name_mapping) +\"\\n\\n\"\n","        # onehot_encoder = OneHotEncoder(sparse_output=False)\n","        # integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","        # onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","        # y=onehot_encoded.astype('uint8')\n","        #return X,y\n","    # split by subject number pass in dictionary\n","    # sub_num = np.ravel(sub[ : , 0] ) # convert shape to (1047,)\n","    # this code is different from typical due to limited subjects,\n","    # all not test subjects data is placed into train which is then \n","    # split using stratification - validation group is not sub independent\n","    # train_index = np.nonzero(np.isin(sub_num, split_subj['train_subj'] + \n","    #                                     split_subj['valid_subj']))\n","    # x_train = X[train_index]\n","    # y_train = y[train_index]\n","    if (incl_val_group):\n","        if not suppress_warn:\n","            print(\"Warning: Due to limited subjects the validation group is a stratified\")\n","            print(\"90/10 split of the training group.  It is not subject independent.\")\n","        # split training into training + validate using stratify - note that the\n","        # validation set is not subject independent (hard to achieve with limited\n","        # subjects).   The test set however is subject independent and as a result\n","        # will have much lower accuracy.  Another option is to tag a few of the\n","        # activities for inclusion in validation.  See\n","        # https://github.com/imics-lab/Semi-Supervised-HAR-e4-Wristband\n","        # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","        x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10, random_state=42, stratify=y_train)\n","\n","    # test_index = np.nonzero(np.isin(sub_num, split_subj['test_subj']))\n","    # x_test = X[test_index]\n","    # y_test = y[test_index]\n","\n","    headers = (\"Returned Array\",\"shape\", \"object type\", \"data type\")\n","    mydata = [(\"x_train:\", x_train.shape, type(x_train), x_train.dtype),\n","                    (\"y_train:\", y_train.shape ,type(y_train), y_train.dtype)]\n","    if (incl_val_group):\n","        mydata += [(\"x_valid:\", x_valid.shape, type(x_valid), x_valid.dtype),\n","                        (\"y_valid:\", y_valid.shape ,type(y_valid), y_valid.dtype)]\n","    mydata += [(\"x_test:\", x_test.shape, type(x_test), x_test.dtype),\n","                    (\"y_test:\", y_test.shape ,type(y_test), y_test.dtype)]\n","    if (verbose):\n","        print(tabulate(mydata, headers=headers))\n","    log_info += tabulate(mydata, headers=headers)\n","    if (incl_val_group):\n","        if (return_info_dict):\n","            return x_train, y_train, x_valid, y_valid, x_test, y_test, log_info\n","        else:\n","            return x_train, y_train, x_valid, y_valid, x_test, y_test\n","    else:\n","        if (return_info_dict):\n","            return x_train, y_train, x_test, y_test, log_info\n","        else:\n","            return x_train, y_train, x_test, y_test\n"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Main is setup to be a demo and bit of unit test."],"metadata":{"id":"tncwIiZaB3j3"}},{"cell_type":"code","metadata":{"id":"MaT1dfqavvtk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678420072260,"user_tz":360,"elapsed":1111,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}},"outputId":"e8b349ae-9ed3-44c9-cbeb-8f569ad0fc92"},"source":["if __name__ == \"__main__\":\n","    verbose = False\n","    print(\"Get Gesture Phase Segmentation using defaults - simple and easy!\")\n","    x_train, y_train, x_test, y_test \\\n","                             = gesture_phase_segmentation_load_dataset()\n","    headers = (\"Array\",\"shape\", \"data type\")\n","    mydata = [(\"x_train:\", x_train.shape, x_train.dtype),\n","            (\"y_train:\", y_train.shape, y_train.dtype),\n","            (\"x_test:\", x_test.shape, x_test.dtype),\n","            (\"y_test:\", y_test.shape, y_test.dtype)]\n","    print(\"\\n\",tabulate(mydata, headers=headers))\n","    print ('\\n','-'*72)\n","\n","    print(\"Get Gesture Phase Segmentation with validation and info file\\n\")\n","    x_train, y_train, x_valid, y_valid, x_test, y_test, log_info \\\n","                             = gesture_phase_segmentation_load_dataset(\n","                                 incl_val_group = True,\n","                                 return_info_dict = True)\n","\n","    headers = (\"Array\",\"shape\", \"data type\")\n","    mydata = [(\"x_train:\", x_train.shape, x_train.dtype),\n","            (\"y_train:\", y_train.shape, y_train.dtype),\n","            (\"x_valid:\", x_valid.shape, x_valid.dtype),\n","            (\"y_valid:\", y_valid.shape, y_valid.dtype),\n","            (\"x_test:\", x_test.shape, x_test.dtype),\n","            (\"y_test:\", y_test.shape, y_test.dtype)]\n","    print(\"\\n\",tabulate(mydata, headers=headers))\n","    print(\"\\n----------- Contents of returned log_info ---------------\")\n","    print(log_info)\n","    print(\"\\n------------- End of returned log_info -----------------\")"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Get Gesture Phase Segmentation using defaults - simple and easy!\n","Downloading Gesture-Phase-Segmentation dataset from UCI ML Repository\n","Unzipping Gesture Phase Segmentation file in ./gesture_phase_dataset directory\n","Train: dict_keys(['a1_raw', 'a2_raw', 'a3_raw', 'b1_raw', 'b3_raw'])\n","Valid: dict_keys([])\n","Test : dict_keys(['c1_raw', 'c3_raw'])\n","\n"," Array     shape          data type\n","--------  -------------  -----------\n","x_train:  (469, 30, 18)  float32\n","y_train:  (469, 5)       float64\n","x_test:   (501, 30, 18)  float32\n","y_test:   (501, 5)       float64\n","\n"," ------------------------------------------------------------------------\n","Get Gesture Phase Segmentation with validation and info file\n","\n","Train: dict_keys(['a1_raw', 'a2_raw', 'a3_raw', 'b1_raw', 'b3_raw'])\n","Valid: dict_keys([])\n","Test : dict_keys(['c1_raw', 'c3_raw'])\n","Warning: Due to limited subjects the validation group is a stratified\n","90/10 split of the training group.  It is not subject independent.\n","\n"," Array     shape          data type\n","--------  -------------  -----------\n","x_train:  (422, 30, 18)  float32\n","y_train:  (422, 5)       float64\n","x_valid:  (47, 30, 18)   float32\n","y_valid:  (47, 5)        float64\n","x_test:   (501, 30, 18)  float32\n","y_test:   (501, 5)       float64\n","\n","----------- Contents of returned log_info ---------------\n","Generated by Gesture-Phase-Segmentation_load_dataset.ipynb\n","March 10, 2023\n","sub dict = {'train_subj': [1, 2], 'valid_subj': [], 'test_subj': [3]}\n","Returned Array    shape          object type              data type\n","----------------  -------------  -----------------------  -----------\n","x_train:          (422, 30, 18)  <class 'numpy.ndarray'>  float32\n","y_train:          (422, 5)       <class 'numpy.ndarray'>  float64\n","x_valid:          (47, 30, 18)   <class 'numpy.ndarray'>  float32\n","y_valid:          (47, 5)        <class 'numpy.ndarray'>  float64\n","x_test:           (501, 30, 18)  <class 'numpy.ndarray'>  float32\n","y_test:           (501, 5)       <class 'numpy.ndarray'>  float64\n","\n","------------- End of returned log_info -----------------\n"]}]}]}