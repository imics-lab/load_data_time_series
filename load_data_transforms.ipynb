{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Srs4MZ7KG4AB4MUDqHS1TEP2bGVc76yT","timestamp":1677189066823},{"file_id":"1Bv9_aEQ4kCEgzPZ-9zjnYUZvbgO_OtA4","timestamp":1677010515769},{"file_id":"1WbviRoNfMEZwPiA0Jm0FruV9l8tODu_e","timestamp":1656703965031},{"file_id":"1RkiXI3GhB-rNtyUp_VYw05xiiuD_oDFA","timestamp":1612028534003}],"authorship_tag":"ABX9TyNHTnWIFwhsHv859QrUdX5D"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Khc4g511HMYk"},"source":["#load_data_transforms.ipynb\n","\n","This is the common code that can be applied to all datasets after the conversion to the standard Intermediate Representation 1 (IR1) dataframe.\n","\n","Set interactive to true to run the Jupyter Notebook version.  Note most of the calls are setup to test the functions, not process the entire dataset, to do that set interactive to false and run all so that main executes.   This notebook can be saved and run as a python file as well.\n","\n","\n","<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n","\n","[Lee B. Hinkle](https://userweb.cs.txstate.edu/~lbh31/), Texas State University, [IMICS Lab](https://imics.wp.txstate.edu/)  \n","TODO:\n","* This is in-progress - current focus is on the Gesture dataset so testing will need to be done with the others.\n","* Issue with !gdown not running in a function is a pain.\n","* assign_ints_ir1_labels() seems to still return an int64 instead of int8\n","* get_ir2_from_ir1(df) only handles a single 'label' column, needs update based on the keys in the label_map dict.  Sub column is also hardcoded in this function, should at least check for 'sub' and 'subject'\n","* Needs at least a basic _init_ unit test to be able to generate some output when checking as a .py\n"]},{"cell_type":"code","metadata":{"id":"q6H67o-YARCx","executionInfo":{"status":"ok","timestamp":1677950527955,"user_tz":360,"elapsed":10063,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["import os\n","import shutil #https://docs.python.org/3/library/shutil.html\n","from shutil import unpack_archive # to unzip\n","import time\n","import pandas as pd\n","import numpy as np\n","from numpy import savetxt\n","from tabulate import tabulate # for verbose tables, showing data\n","from tensorflow.keras.utils import to_categorical # for one-hot encoding\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from time import gmtime, strftime, localtime #for displaying Linux UTC timestamps in hh:mm:ss\n","from datetime import datetime, date\n","import urllib.request # to get files from web w/o !wget\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Global Parameters"],"metadata":{"id":"iDsgBVo_BFkc"}},{"cell_type":"code","metadata":{"id":"1LkvTO5hujPH","executionInfo":{"status":"ok","timestamp":1677950527956,"user_tz":360,"elapsed":6,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["# environment and execution parameters\n","my_dir = '.' # replace with absolute path if desired\n","dataset_dir = os.path.join(my_dir,'gesture_phase_dataset') # Where dataset will be unzipped\n","\n","interactive = True # for exploring data and functions interactively\n","verbose = True\n","\n","# dataset parameters\n","# These are here for debugging, need to be set for each dataset\n","# since these values very much depend on the nature of the data and are also\n","# important hyperparameters for evaluation.\n","time_steps = 32 \n","stride = 8\n","\n","# example of how to load these transforms and set params in loader:\n","# import load_data_transforms as xform\n","# xform.time_steps = 96 # three seconds at 32Hz\n","# xform.stride = 32 # one second step for each sliding window"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"_arxQU-n6nKK","executionInfo":{"status":"ok","timestamp":1677950527957,"user_tz":360,"elapsed":6,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["interactive = False # don't run if interactive, automatically runs for .py version\n","verbose = False # to limit the called functions output"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Get IR1 dataframes for interactive testing."],"metadata":{"id":"b75gKthUPKQD"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"46F53M4ZE7gx","executionInfo":{"status":"ok","timestamp":1677950528170,"user_tz":360,"elapsed":219,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"outputs":[],"source":["if interactive:\n","    print (\"What?\")\n","#Weird - gdown fails when called inside function.  Hack for now...\n","\n","# !gdown \"11OWxTejlTlR53s3RZbSNZdyMdFiN4dZl&confirm=t\" # Gesture Phase Raw IR1s in zip\n","# shutil.unpack_archive('Gesture_Phase_Raw_IR1.zip', my_dir, 'zip')\n","# ir1_df = pd.read_pickle(\"a1_raw.pkl\")\n","# ir1_df.head(5)"]},{"cell_type":"markdown","source":["# Shared transforms"],"metadata":{"id":"svbf8hj0JQ9z"}},{"cell_type":"code","source":["def assign_ints_ir1_labels(df, label_mapping_dict):\n","    \"\"\"Uses the mapping in the passed dictionary to assign integers to each\n","    string value predictably.  This is important because all labels may not\n","    be represented in each IR1 and strings take up too much room in IR2.\n","    Args:\n","        df - an IR1 dataframe with categorical label column\n","        label_mapping_dict - dict of dicts for each label column. See code.\n","    Returns:\n","        df - an updated IR1+ dataframe\"\"\"\n","    # Want to predictably convert the label strings into integers.\n","    # The sklearn label encoder is certainly an option but already have\n","    # a Pandas dataframe.   More importantly I want to encode the values\n","    # using all possible options not just the ones present in this particular\n","    # dataframe.   That means building a dictionary of the label mappings\n","    # which may even include labels not in the dataset at all, such as the\n","    # case with PSG-Audio.   Finally, I want to avoid ever having strings in the\n","    # numpy arrays - not an issue for small datasets but a big memory user\n","    # for larger ones.\n","    # Credit to this nice writeup https://pbpython.com/categorical-encoding.html\n","    if verbose:\n","        print(\"assign_ints_ir1_labels() converting categorical strings to ints\")\n","        print(\"df['label'] value counts\")\n","        print(df['label'].value_counts())\n","        if df['label'].dtype.name == 'category':\n","            dict( zip( df['label'].cat.codes, df['label'] ) ) # shows mapping Pandas is using.\n","    df = df.replace(label_mapping_dict)\n","    df['label']=df['label'].astype('int8') # TODO this only works with single label\n","    return df\n","\n","if interactive:\n","    # This label mapping for Gesture-Phase-Segmentation dataset is in the order\n","    # of the readme.txt.  A second label entry can be added - see url above.\n","    label_map_gps = {\"label\":     {\"Rest\": 0, \"Preparation\": 1, \"Stroke\": 2,\n","                                   \"Hold\": 3, \"Retraction\": 4}}\n","    ir1_df = assign_ints_ir1_labels(ir1_df, label_mapping_dict = label_map_gps)"],"metadata":{"id":"9eGF6qfr7uVN","executionInfo":{"status":"ok","timestamp":1677950528172,"user_tz":360,"elapsed":7,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def get_ir2_from_ir1(df):\n","    \"\"\"slice the IR1 dataframe into sliding window segments of\n","    time_steps length and return X, y, sub, ss_times ndarrays.\n","    If stride = time_steps there is no overlap of the sliding window.\n","    This version does not use append, better for RAM\n","    df: pandas datetime indexed dataframe columns - channel(s), label, sub\n","    Global params used\n","    time_steps: number of samples in window, will discard a partial final window\n","    stride:  how far to move window, no overlap if equal to time_steps.\n","    Returns:\n","    X : ndarray of float32 shape(instances,timesteps,channels))\n","    y : ndarray of int8 labels of shape (instances, labels)\n","    sub : ndarray of int16 subject numbers shape (instances,1)\n","    ss_times : ndarray of datetime64 containing the start and stop time of \n","        each window for label cleaning shape (instances, 2)\n","    channel_list : list of channels, df column names minus 'label' and 'sub'\n","    \"\"\"    \n","    # this was copied from SHL with improved memory capabilities\n","    # TODO:  Update with multi-label version from PSG-Audio\n","    # TODO:  Should confirm datetimes are contiguous and warn if not.\n","    \n","    # the channel list is in dataframe but not in the numpy arrays\n","    channel_list = list(df.columns)\n","    channel_list.remove('label') # need to make sure this is defined for IR1\n","    channel_list.remove('sub') # ditto - should probably add a check\n","    if verbose:\n","        print('Channels in X:',channel_list)\n","    X = df[channel_list].to_numpy(dtype = 'float32')\n","    y = df['label'].to_numpy(dtype = 'int8') # doesn't work for strings\n","    #y = df['label'].to_numpy(dtype='<U10') # use assign_ints_ir1_labels first\n","    sub = df['sub'].to_numpy(dtype = 'int16') # for datasets with sub #s > 255\n","    if verbose:\n","        print('X,y,sub array shapes before sliding window', X.shape, y.shape, sub.shape)\n","    #https://numpy.org/devdocs/reference/generated/numpy.lib.stride_tricks.sliding_window_view.html\n","    shapex = (time_steps,X.shape[1]) # samples (rows to include) and n-dim of original (all channels)\n","    shapey = (time_steps,) # samples (rows to include) and only one column\n","    shapesub = (time_steps,) # samples (rows to include) and only one column\n","    X = np.lib.stride_tricks.sliding_window_view(X, shapex)[::stride, :]\n","    X = X[:,0,:,:] # I admit I don't understand why this dimension appears...\n","    y = np.lib.stride_tricks.sliding_window_view(y, shapey)[::stride, :]\n","    sub = np.lib.stride_tricks.sliding_window_view(sub, shapesub)[::stride, :]\n","    # Build a numpy array of the start and stop timestamps for each sliding\n","    # window - the IR1 indices.  This is to help label cleaning if needed.\n","    timestamps_np = df.index.to_numpy(dtype = 'datetime64')\n","    shape_ts = (time_steps,) # samples (rows to include) and only one column\n","    timestamps_np = np.lib.stride_tricks.sliding_window_view(timestamps_np, shape_ts)[::stride, :]\n","    start_times = timestamps_np[:,0]\n","    stop_times = timestamps_np[:,-1]\n","    ss_times = np.column_stack((start_times,stop_times))\n","    if verbose:\n","        print('X,y,sub,ss_times array shapes after sliding window', X.shape, y.shape, sub.shape, ss_times.shape)\n","    return X, y, sub, ss_times, channel_list\n","if interactive:\n","    my_X, my_y, my_sub, my_ss_times, all_channel_list = get_ir2_from_ir1(ir1_df)\n","    headers = (\"array\",\"shape\", \"object type\", \"data type\")\n","    mydata = [(\"my_X:\", my_X.shape, type(my_X), my_X.dtype),\n","            (\"my_y:\", my_y.shape ,type(my_y), my_y.dtype),\n","            (\"my_sub:\", my_sub.shape, type(my_sub), my_sub.dtype),\n","            (\"my_ss_times:\", my_ss_times.shape, type(my_ss_times), my_ss_times.dtype)]\n","    print(\"IR2 array info\")\n","    print(tabulate(mydata, headers=headers))\n","    print(\"Returned all_channel_list\", all_channel_list)"],"metadata":{"id":"8tzvWPWkYjJq","executionInfo":{"status":"ok","timestamp":1677950528358,"user_tz":360,"elapsed":192,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def clean_ir2(X, y, sub, ss_times):\n","    \"\"\"removes sliding windows containing NaN, multiple labels, or multiple\n","    subject numbers.  Collapses y, sub to column arrays.\n","    Returns cleaned versions of X, y, sub, ss_times ndarrays\"\"\"\n","    # TODO:  This really should be split into multiple functions\n","    # Check for NaN\n","    nans = np.argwhere(np.isnan(X))\n","    num_nans = np.unique(nans[:,0]) #[:,0] just 1st column index of rows w/ NaN\n","    if verbose:\n","        print(num_nans.shape[0], \"NaN entries found, removing\")\n","    idx = ~np.isnan(X).any(axis=2).any(axis=1)\n","    # this warrants some explanation!\n","    # any(axis=1) and 2 collapses channels and samples\n","    # good axis explanation https://www.sharpsightlabs.com/blog/numpy-axes-explained/\n","    # the ~ negates so NaN location are now False in the idx which is then\n","    # used to filter out the bad windows below\n","    X = X[idx]\n","    y = y[idx]\n","    sub = sub[idx]\n","    ss_times = ss_times[idx]\n","    # repeat and confirm NaNs have been removed\n","    nans = np.argwhere(np.isnan(X))\n","    num_nans = np.unique(nans[:,0]) #[:,0] accesses just 1st column\n","    if (nans.size!=0):\n","        print(\"WARNING! Cleaned output arrays still contain NaN entries\")\n","        print(\"execute print(X[99]) # to view single sample\")\n","    # Now get rid of segments with multiple labels\n","    # Not happy with this code, must be a better way but it seems to work...\n","    idx = []\n","    for i in range(y.shape[0]):\n","        if np.all(y[i] == y[i][0]):\n","            idx.append(True)\n","            \n","        else:\n","            idx.append(False)\n","            #print('Discarding Row:', i)\n","    X = X[idx]\n","    y = y[idx]\n","    sub = sub[idx]\n","    ss_times = ss_times[idx]\n","    # TODO check for multiple subjects in window\n","    y = y[:,0] # collapse columns\n","    y = y[np.newaxis].T  # convert to single column array\n","    sub = sub[:,0] # repeat for sub array\n","    sub = sub[np.newaxis].T\n","    return X, y, sub, ss_times\n","if interactive:\n","    my_X, my_y, my_sub, my_ss_times = clean_ir2(my_X, my_y, my_sub, my_ss_times)\n","    print('IR2 shapes after cleaning', my_X.shape, my_y.shape, my_sub.shape)\n","    headers = (\"array\",\"shape\", \"object type\", \"data type\")\n","    mydata = [(\"my_X:\", my_X.shape, type(my_X), my_X.dtype),\n","            (\"my_y:\", my_y.shape ,type(my_y), my_y.dtype),\n","            (\"my_sub:\", my_sub.shape, type(my_sub), my_sub.dtype),\n","            (\"my_ss_times:\", my_ss_times.shape, type(my_ss_times), my_ss_times.dtype)]\n","    print(\"IR2 array info\")\n","    print(tabulate(mydata, headers=headers))"],"metadata":{"id":"eUwME1geL_X0","executionInfo":{"status":"ok","timestamp":1677950528359,"user_tz":360,"elapsed":193,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def drop_label_ir2_ir3(X, y, sub, ss_times, label_to_drop):\n","    \"\"\"removes windows with label = label_to_drop\n","    This is primarily used to remove invalid windows, such as 'unknown' = 99\n","    Returns updated version of X, y, sub\"\"\"\n","    idx = []\n","    for i in range(y.shape[0]):\n","        if (y[i] == label_to_drop):\n","            idx.append(False)\n","        else:\n","            idx.append(True)\n","            #print('Discarding Row:', i)\n","    X = X[idx]\n","    y = y[idx]\n","    sub = sub[idx]\n","    ss_times = ss_times[idx]\n","    return X, y, sub, ss_times\n","if interactive:\n","    print(\"Label counts before drop\")\n","    unique, counts = np.unique(my_y, return_counts=True)\n","    print (np.asarray((unique, counts)).T)\n","    print('X, y, sub array shapes before label drop', my_X.shape, my_y.shape, my_sub.shape)\n","    my_X, my_y, my_sub, my_ss_times = drop_label_ir2_ir3(my_X, my_y, my_sub,my_ss_times, 2)\n","    print(\"Label counts after drop\")\n","    unique, counts = np.unique(my_y, return_counts=True)\n","    print (np.asarray((unique, counts)).T)\n","    print('IR2 shapes after label drop', my_X.shape, my_y.shape, my_sub.shape)\n","    headers = (\"array\",\"shape\", \"object type\", \"data type\")\n","    mydata = [(\"my_X:\", my_X.shape, type(my_X), my_X.dtype),\n","            (\"my_y:\", my_y.shape ,type(my_y), my_y.dtype),\n","            (\"my_sub:\", my_sub.shape, type(my_sub), my_sub.dtype),\n","            (\"my_ss_times:\", my_ss_times.shape, type(my_ss_times), my_ss_times.dtype)]\n","    print(\"IR2 array info after label drop\")\n","    print(tabulate(mydata, headers=headers))"],"metadata":{"id":"JWVaxg08-06G","executionInfo":{"status":"ok","timestamp":1677950528528,"user_tz":360,"elapsed":172,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q38LmSybsG3r","executionInfo":{"status":"ok","timestamp":1677950528528,"user_tz":360,"elapsed":4,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["def get_ir3_from_dict(ir1_dict, label_map):\n","    \"\"\"Processes a dictionary and combines the IR1 dataframes into a single\n","    IR3 set of numpy arrays.  Converts string labels to integers based on the\n","    passed label map.\n","    Params:\n","    ir1_dict: dict of IR1 dataframes key = IR1 source filename, item = IR1 df\n","    label_map: dict of labels (one entry per label column, most datasets will\n","         have only one with key = 'label'.  The item is a dict with keys of \n","         all possible strings and item = corresponding int.)\n","    num_channels: the number of data channels (# df columns - #labels - 1 for sub)\n","    Returns:\n","    X - ndarray (float32) of all channels\n","    y - ndarray (int8) of labels, for multi-label datasets # labels = # columns\n","    sub - ndarray (int16) subject number, int16 allows for sub nums > 255\n","    ss_times - ndarray (datetime64), start and stop time for sliding window\n","    xys_info - string, basically an autogenerated readme (needs work)\n","    \"\"\"\n","    # NOTE - this is really hard to debug since an ir1_dict is required.\n","    # I've been just working on it in the TWRistAR loader paste the working code here.\n","    # Need to figure out number of channels for original array dimensions\n","    df_list = list(ir1_dict) # ir1_dict.keys() returns a dict_keys type\n","    col_list = list(ir1_dict[df_list[0]].columns) # all columns in df\n","    label_list = list(label_map) # in case of multi-labeled dataset\n","    label_list.append('sub') # this really should be tested and not hard-coded\n","    # ref https://www.geeksforgeeks.org/python-remove-all-values-from-a-list-present-in-other-list/\n","    #ch_list = list(set(col_list) - set(label_list)) # don't do this - it reorders list!\n","    for i in label_list:\n","        try:\n","            col_list.remove(i)\n","        except ValueError:\n","            pass\n","\n","    num_channels = len(col_list)\n","    ir3_X = np.zeros(shape=(1,time_steps,num_channels), dtype = 'float32')\n","    ir3_y = np.zeros(shape=(1,1),dtype='int8') # ints - strings take too much space\n","    #ir3_y = np.full(shape=(1,1), fill_value='n/a',dtype='<U10') # unicode 10 char\n","    ir3_sub = np.zeros(shape=(1,1),dtype='int16') # some dataset have sub# > 255\n","    ir3_ss_times = np.zeros(shape=(1,2),dtype='datetime64') # start/stop times of sliding window\n","    for ir1_fname, ir1_df in ir1_dict.items():\n","        if verbose:\n","            print('Processing ', ir1_fname)\n","        ir1_df = assign_ints_ir1_labels(ir1_df, label_mapping_dict = label_map)\n","        ir2_X, ir2_y, ir2_sub, ir2_ss_time, channel_list = get_ir2_from_ir1(ir1_df)\n","        ir2_X, ir2_y, ir2_sub, ir2_ss_time = clean_ir2(ir2_X, ir2_y, ir2_sub, ir2_ss_time)\n","        ir2_X, ir2_y, ir2_sub, ir2_ss_time = drop_label_ir2_ir3(ir2_X, ir2_y, ir2_sub, ir2_ss_time, 99)\n","        ir3_X = np.vstack([ir3_X, ir2_X])\n","        ir3_y = np.vstack([ir3_y, ir2_y])\n","        ir3_sub = np.vstack([ir3_sub, ir2_sub])\n","        ir3_ss_times = np.vstack([ir3_ss_times, ir2_ss_time])\n","    #delete first row placeholders\n","    X = np.delete(ir3_X, (0), axis=0) \n","    y = np.delete(ir3_y, (0), axis=0) \n","    sub = np.delete(ir3_sub, (0), axis=0)\n","    sub = np.delete(ir3_sub, (0), axis=0)\n","    ss_times = np.delete(ir3_ss_times, (0), axis=0)\n","\n","    xys_info = 'Needs work!\\n'\n","    # xys_info += '\\n'.join([str(elem) for elem in zip_flist]) # conv list to string\n","    # xys_info += '\\nTime steps =' + str(time_steps) + ', Step =' + str(stride) + ', no resample\\n'\n","    # xys_info += 'Final Shapes\\n'\n","    # xys_info += \"X shape \" + str(X.shape) + \" dtype = \" + str(X.dtype) + \"\\n\"\n","    # xys_info += \"y shape \" + str(y.shape) + \" dtype = \" + str(y.dtype) + \"\\n\"\n","    # xys_info += \"sub shape \" + str(sub.shape) + \" dtype = \" + str(sub.dtype) + \"\\n\"\n","    xys_info += \"IR1 Channel names:\" + str(channel_list) + \"\\n\"\n","    # # Get final counts for label ndarray - not quite as easy as pandas df\n","    # xys_info += \"Final Label Counts\\n\"\n","    # unique, counts = np.unique(y, return_counts=True)\n","    # xys_info += str(np.asarray((unique, counts)).T)\n","    # xys_info += \"\\nSamples per Subject\\n\"\n","    # unique, counts = np.unique(sub, return_counts=True)\n","    # xys_info += str(np.asarray((unique, counts)).T)\n","    return X, y, sub, ss_times, xys_info\n","# This was developed using TWristAR and Gesture-Phase-Segmentation but hard\n","# to have a mini-unit test here as it need the IR1 dictionary.\n","# if interactive:\n","#     X, y, sub, ss_times, xys_info = get_ir3_from_dict(ir1_dict, label_map = label_map_twristar, num_channels = 7)\n","#     headers = (\"array\",\"shape\", \"object type\", \"data type\")\n","#     mydata = [(\"X:\", X.shape, type(X), X.dtype),\n","#             (\"y:\", y.shape ,type(y), y.dtype),\n","#             (\"sub:\", sub.shape, type(sub), sub.dtype),\n","#             (\"ss_time:\", ss_times.shape, type(ss_times), ss_times.dtype)]\n","#     print(tabulate(mydata, headers=headers))\n","#     unique, counts = np.unique(y, return_counts=True)\n","#     print('Label Counts:\\n',str(np.asarray((unique, counts)).T))\n","#     print(label_map_twristar)"],"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def limit_channel_ir3(ir3_X, \n","                      all_channel_list,\n","                      keep_channel_list):\n","    \"\"\"Pass the full ir3_X array with all channels, the stored all_channel_list\n","    that was extracted from the ir1 dataframe column names, and a \n","    keep_channel_list.  Matching channels will be kept, all others dropped.\"\"\"\n","    # This would have been much easier at IR1 but that would precluded channel \n","    # experiments and by channel feature representations.  I'm still torn on\n","    # whether dropping at IR1 would be better because it could be by column\n","    # name instead of list position.\n","    # This is really new code, I'm leaving in some commented statements for now\n","    ch_idx = []\n","    # should add check here for channels not in list\n","    for i in keep_channel_list:\n","        ch_idx.append(all_channel_list.index(i)) \n","    if verbose:\n","        print(\"Keeping X columns at index\", ch_idx)\n","    new_X = ir3_X[:,:,ch_idx]\n","    return new_X\n","if interactive:\n","    print(\"all_channel_list\", all_channel_list)\n","    print(\"starting X shape\", my_X.shape)\n","    print(\"first row\", my_X[0,0,:])\n","    my_new_X = limit_channel_ir3(my_X, all_channel_list,\n","                                 keep_channel_list = ['lhx', 'lhy', 'lhz'])\n","    print(\"ending X shape\", my_new_X.shape)\n","    print(\"first row\", my_new_X[0,0,:])"],"metadata":{"id":"c1WYWW5jzf2-","executionInfo":{"status":"ok","timestamp":1677950528529,"user_tz":360,"elapsed":4,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":10,"outputs":[]}]}