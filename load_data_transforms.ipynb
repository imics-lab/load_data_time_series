{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Srs4MZ7KG4AB4MUDqHS1TEP2bGVc76yT","timestamp":1677189066823},{"file_id":"1Bv9_aEQ4kCEgzPZ-9zjnYUZvbgO_OtA4","timestamp":1677010515769},{"file_id":"1WbviRoNfMEZwPiA0Jm0FruV9l8tODu_e","timestamp":1656703965031},{"file_id":"1RkiXI3GhB-rNtyUp_VYw05xiiuD_oDFA","timestamp":1612028534003}],"authorship_tag":"ABX9TyOuh2lKD17KfwLb4KwgyeMT"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Khc4g511HMYk"},"source":["#load_data_transforms.ipynb\n","\n","This is the common code that can be applied to all datasets after the conversion to the standard Intermediate Representation 1 (IR1) dataframe.\n","\n","Set interactive to true to run the Jupyter Notebook version.  Note most of the calls are setup to test the functions, not process the entire dataset, to do that set interactive to false and run all so that main executes.   This notebook can be saved and run as a python file as well.\n","\n","\n","<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n","\n","[Lee B. Hinkle](https://userweb.cs.txstate.edu/~lbh31/), Texas State University, [IMICS Lab](https://imics.wp.txstate.edu/)  \n","TODO:\n","* This is in-progress - current focus is on the Gesture dataset so testing will need to be done with the others.\n"]},{"cell_type":"code","metadata":{"id":"q6H67o-YARCx","executionInfo":{"status":"ok","timestamp":1677207929652,"user_tz":360,"elapsed":7152,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["import os\n","import shutil #https://docs.python.org/3/library/shutil.html\n","from shutil import unpack_archive # to unzip\n","import time\n","import pandas as pd\n","import numpy as np\n","from numpy import savetxt\n","from tabulate import tabulate # for verbose tables, showing data\n","from tensorflow.keras.utils import to_categorical # for one-hot encoding\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from time import gmtime, strftime, localtime #for displaying Linux UTC timestamps in hh:mm:ss\n","from datetime import datetime, date\n","import urllib.request # to get files from web w/o !wget\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Global Parameters"],"metadata":{"id":"iDsgBVo_BFkc"}},{"cell_type":"code","metadata":{"id":"1LkvTO5hujPH","executionInfo":{"status":"ok","timestamp":1677207929653,"user_tz":360,"elapsed":28,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["# environment and execution parameters\n","my_dir = '.' # replace with absolute path if desired\n","dataset_dir = os.path.join(my_dir,'gesture_phase_dataset') # Where dataset will be unzipped\n","\n","interactive = True # for exploring data and functions interactively\n","verbose = True\n","\n","# dataset parameters\n","time_steps = 32\n","stride = 8"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"_arxQU-n6nKK","executionInfo":{"status":"ok","timestamp":1677207929654,"user_tz":360,"elapsed":28,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"source":["interactive = False # don't run if interactive, automatically runs for .py version\n","verbose = False # to limit the called functions output"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Get IR1 dataframes for interactive testing."],"metadata":{"id":"b75gKthUPKQD"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"46F53M4ZE7gx","executionInfo":{"status":"ok","timestamp":1677207929655,"user_tz":360,"elapsed":29,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"outputs":[],"source":["if interactive:\n","    !gdown \"11OWxTejlTlR53s3RZbSNZdyMdFiN4dZl&confirm=t\" # Gesture Phase Raw IR1s in zip\n","    shutil.unpack_archive('Gesture_Phase_Raw_IR1.zip', my_dir, 'zip')\n","    ir1_df = pd.read_pickle(\"a1_raw.pkl\")\n","    # ir1_df.rename(columns={\"phase\": \"label\"}, inplace = True, errors=\"raise\") # phase was GPS dataset specific\n","    # ir1_df.rename(columns={\"subject\": \"sub\"}, inplace = True, errors=\"raise\") # subject versus sub too\n","    # ir1_df['sub'] = [ ord(x) - 96 for x in ir1_df['sub']] # ord is unicode char\n","    ir1_df.head()"]},{"cell_type":"markdown","source":["# Shared transforms"],"metadata":{"id":"svbf8hj0JQ9z"}},{"cell_type":"code","source":["def get_ir2_from_ir1(df):\n","    \"\"\"slice the IR1 dataframe into sliding window segments of\n","    time_steps length and return X, y, sub ndarrays.\n","    If stride = time_steps there is no overlap of the sliding window.\n","    This version does not use append, better for RAM\n","    df: pandas datetime indexed dataframe columns - channel(s), label, sub\n","    Global params used\n","    time_steps: number of samples in window, will discard a partial final window\n","    stride:  how far to move window, no overlap if equal to time_steps.\n","    \"\"\"    \n","    # this was copied from SHL with improved memory capabilities\n","    # TODO:  Update with multi-label version from PSG-Audio\n","    # the channel list is in dataframe but not in the numpy arrays\n","    channel_list = list(df.columns)\n","    channel_list.remove('label') # need to make sure this is defined for IR1\n","    channel_list.remove('sub') # ditto - should probably add a check\n","    if verbose:\n","        print('Channels in X:',channel_list)\n","    X = df[channel_list].to_numpy(dtype = 'float32')\n","    #y = df['label'].to_numpy(dtype = 'int8') # doesn't work for strings\n","    y = df['label'].to_numpy(dtype='<U10')\n","    sub = df['sub'].to_numpy(dtype = 'int8')\n","    if verbose:\n","        print('X,y,sub array shapes before sliding window', X.shape, y.shape, sub.shape)\n","    #https://numpy.org/devdocs/reference/generated/numpy.lib.stride_tricks.sliding_window_view.html\n","    shapex = (time_steps,X.shape[1]) # samples (rows to include) and n-dim of original (all channels)\n","    shapey = (time_steps,) # samples (rows to include) and only one column\n","    shapesub = (time_steps,) # samples (rows to include) and only one column\n","    X = np.lib.stride_tricks.sliding_window_view(X, shapex)[::stride, :]\n","    X = X[:,0,:,:] # I admit I don't understand why this dimension appears...\n","    y = np.lib.stride_tricks.sliding_window_view(y, shapey)[::stride, :]\n","    sub = np.lib.stride_tricks.sliding_window_view(sub, shapesub)[::stride, :]\n","    if verbose:\n","        print('X,y,sub array shapes after sliding window', X.shape, y.shape, sub.shape)\n","    return X, y, sub, channel_list\n","if interactive:\n","    my_X, my_y, my_sub, all_channel_list = get_ir2_from_ir1(ir1_df)\n","    headers = (\"array\",\"shape\", \"object type\", \"data type\")\n","    mydata = [(\"my_X:\", my_X.shape, type(my_X), my_X.dtype),\n","            (\"my_y:\", my_y.shape ,type(my_y), my_y.dtype),\n","            (\"my_sub:\", my_sub.shape, type(my_sub), my_sub.dtype)]\n","    print(\"IR2 array info\")\n","    print(tabulate(mydata, headers=headers))\n","    print(\"Returned all_channel_list\", all_channel_list)"],"metadata":{"id":"8tzvWPWkYjJq","executionInfo":{"status":"ok","timestamp":1677207929655,"user_tz":360,"elapsed":28,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def clean_ir2(X, y, sub):\n","    \"\"\"removes sliding windows containing NaN, multiple labels, or multiple\n","    subject numbers.  Collapses y, sub to column arrays.\n","    Returns cleaned versions of X, y, sub ndarrays\"\"\"\n","    # Copied directly from SHL.  Yay!\n","    # Check for NaN\n","    nans = np.argwhere(np.isnan(X))\n","    num_nans = np.unique(nans[:,0]) #[:,0] just 1st column index of rows w/ NaN\n","    if verbose:\n","        print(num_nans.shape[0], \"NaN entries found, removing\")\n","    idx = ~np.isnan(X).any(axis=2).any(axis=1)\n","    # this warrants some explanation!\n","    # any(axis=1) and 2 collapses channels and samples\n","    # good axis explanation https://www.sharpsightlabs.com/blog/numpy-axes-explained/\n","    # the ~ negates so NaN location are now False in the idx which is then\n","    # used to filter out the bad windows below\n","    X = X[idx]\n","    y = y[idx]\n","    sub = sub[idx]\n","    # repeat and confirm NaNs have been removed\n","    nans = np.argwhere(np.isnan(X))\n","    num_nans = np.unique(nans[:,0]) #[:,0] accesses just 1st column\n","    if (nans.size!=0):\n","        print(\"WARNING! Cleaned output arrays still contain NaN entries\")\n","        print(\"execute print(X[99]) # to view single sample\")\n","    # Now get rid of segments with multiple labels\n","    # Not happy with this code, must be a better way but it seems to work...\n","    idx = []\n","    for i in range(y.shape[0]):\n","        if np.all(y[i] == y[i][0]):\n","            idx.append(True)\n","            \n","        else:\n","            idx.append(False)\n","            #print('Discarding Row:', i)\n","    X = X[idx]\n","    y = y[idx]\n","    sub = sub[idx]\n","    # TODO check for multiple subjects in window\n","    y = y[:,0] # collapse columns\n","    y = y[np.newaxis].T  # convert to single column array\n","    sub = sub[:,0] # repeat for sub array\n","    sub = sub[np.newaxis].T\n","    return X, y, sub\n","if interactive:\n","    my_X, my_y, my_sub = clean_ir2(my_X, my_y, my_sub)\n","    print('IR2 shapes after cleaning', my_X.shape, my_y.shape, my_sub.shape)\n","    headers = (\"array\",\"shape\", \"object type\", \"data type\")\n","    mydata = [(\"my_X:\", my_X.shape, type(my_X), my_X.dtype),\n","            (\"my_y:\", my_y.shape ,type(my_y), my_y.dtype),\n","            (\"my_sub:\", my_sub.shape, type(my_sub), my_sub.dtype)]\n","    print(\"IR2 array info\")\n","    print(tabulate(mydata, headers=headers))"],"metadata":{"id":"eUwME1geL_X0","executionInfo":{"status":"ok","timestamp":1677207929656,"user_tz":360,"elapsed":28,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def drop_label_ir2_ir3(X, y, sub, label_to_drop):\n","    \"\"\"removes windows with label = label_to_drop\n","    This is primarily used to remove invalid windows, such as 'unknown' label\n","    Returns updated version of X, y, sub\"\"\"\n","    # Also copied directly from SHL - double Yay!\n","    idx = []\n","    for i in range(y.shape[0]):\n","        if (y[i] == label_to_drop):\n","            idx.append(False)\n","        else:\n","            idx.append(True)\n","            #print('Discarding Row:', i)\n","    X = X[idx]\n","    y = y[idx]\n","    sub = sub[idx]\n","    return X, y, sub\n","if interactive:\n","    print(\"Label counts before drop\")\n","    unique, counts = np.unique(my_y, return_counts=True)\n","    print (np.asarray((unique, counts)).T)\n","    print('X, y, sub array shapes before label drop', my_X.shape, my_y.shape, my_sub.shape)\n","    my_X, my_y, my_sub = drop_label_ir2_ir3(my_X, my_y, my_sub, 'Undefined')\n","    print(\"Label counts after drop\")\n","    unique, counts = np.unique(my_y, return_counts=True)\n","    print (np.asarray((unique, counts)).T)\n","    print('IR2 shapes after label drop', my_X.shape, my_y.shape, my_sub.shape)\n","    headers = (\"array\",\"shape\", \"object type\", \"data type\")\n","    mydata = [(\"my_X:\", my_X.shape, type(my_X), my_X.dtype),\n","            (\"my_y:\", my_y.shape ,type(my_y), my_y.dtype),\n","            (\"my_sub:\", my_sub.shape, type(my_sub), my_sub.dtype)]\n","    print(\"IR2 array info after label drop\")\n","    print(tabulate(mydata, headers=headers))"],"metadata":{"id":"JWVaxg08-06G","executionInfo":{"status":"ok","timestamp":1677207929656,"user_tz":360,"elapsed":28,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def limit_channel_ir3(ir3_X, \n","                      all_channel_list = ['accel_x', 'accel_y', 'accel_z', 'accel_ttl', 'bvp', 'eda', 'p_temp'],\n","                      keep_channel_list = [\"accel_ttl\"]):\n","    \"\"\"Pass the full ir3_X array with all channels, the stored all_channel_list\n","    that was extracted from the ir1 dataframe column names, and a \n","    keep_channel_list.  Matching channels will be kept, all others dropped.\n","    This would have been much easier at IR1 but that would precluded channel \n","    experiments and by channel feature representations.\n","    This is really new code, I'm leaving in some commented statements for now\"\"\"\n","    ch_idx = []\n","    # should add check here for channels not in list\n","    for i in keep_channel_list:\n","        ch_idx.append(all_channel_list.index(i)) \n","    if verbose:\n","        print(\"Keeping X columns at index\", ch_idx)\n","    new_X = ir3_X[:,:,ch_idx]\n","    return new_X\n","if interactive:\n","    print(\"all_channel_list\", all_channel_list)\n","    print(\"starting X shape\", my_X.shape)\n","    print(\"first row\", my_X[0,0,:])\n","    my_new_X = limit_channel_ir3(my_X,\n","                                 keep_channel_list = ['accel_ttl','p_temp'])\n","    print(\"ending X shape\", my_new_X.shape)\n","    print(\"first row\", my_new_X[0,0,:])"],"metadata":{"id":"c1WYWW5jzf2-","executionInfo":{"status":"ok","timestamp":1677207929657,"user_tz":360,"elapsed":28,"user":{"displayName":"Lee Hinkle","userId":"00071704663307985880"}}},"execution_count":8,"outputs":[]}]}